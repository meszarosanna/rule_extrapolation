{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Setup and imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "from tueplots import bundles, figsizes\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import sys\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "sys.path.insert(0, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from analysis import sweep2df, plot_typography, stats2string, RED, BLUE, rule_stats2string_per_model, grouped_rule_stats\n",
    "from llm_non_identifiability.data import A_token, B_token, OPENING_BRACKET_token, OPENING_PARENTHESIS_token, CLOSING_BRACKET_token, CLOSING_PARENTHESIS_token"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "USETEX = True"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.rcParams.update(bundles.icml2022(usetex=USETEX))\n",
    "# plt.rcParams.update({\n",
    "#     'text.latex.preamble': [r'\\usepackage{amsfonts}', # mathbb\n",
    "#                             r'\\usepackage{amsmath}'] # boldsymbol\n",
    "# })"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_typography(usetex=USETEX, small=12, medium=16, big=20)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Constants\n",
    "ENTITY = \"causal-representation-learning\"\n",
    "PROJECT = \"rule_extrapolation\"\n",
    "\n",
    "# W&B API\n",
    "api = wandb.Api(timeout=200)\n",
    "runs = api.runs(ENTITY + \"/\" + PROJECT)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data loading"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_sweep_stats(sweep_id, file_prefix, save=False, load=True, entity=ENTITY, project=PROJECT):\n",
    "    api = wandb.Api(timeout=200)\n",
    "    sweep = api.sweep(f\"{entity}/{project}/{sweep_id}\")\n",
    "    filename = f\"{file_prefix}_{sweep_id}\"\n",
    "    df,train_loss,val_loss,val_kl,val_accuracy,finised,ood_finised,sos_finised,r1,r2,grammatical,ood_r1,ood_r1_completion,ood_r2,ood_grammatical,sos_r1,sos_r2,sos_grammatical= sweep2df(sweep.runs, filename, save=save, load=load)\n",
    "    return df, grouped_rule_stats(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## baN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# SWEEP_ID = \"y2193u7e\"\n",
    "ban_no_transformer_df, ban_no_transformer_stats = get_sweep_stats(sweep_id=\"frrbkgg0\", file_prefix=\"ban_no_transformer\", save=True, load=False)\n",
    "ban_transformer_df, ban_transformer_stats = get_sweep_stats(sweep_id=\"9b9a0xtn\", file_prefix=\"ban_transformer\", save=True, load=False)\n",
    "ban_lstm_df, ban_lstm_stats = get_sweep_stats(sweep_id=\"vzcozopj\", file_prefix=\"ban_lstm\", save=True, load=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ban_df = pd.concat([ban_no_transformer_df, ban_transformer_df])\n",
    "ban_stats = grouped_rule_stats(ban_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## bbaN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bban_transformer_mamba_df, bban_transformer_mamba_stats = get_sweep_stats(sweep_id=\"jjjtbh24\", file_prefix=\"bban_transformer_mamba\", save=True, load=False)\n",
    "bban_all_df, bban_all_stats = get_sweep_stats(sweep_id=\"unc8bv65\", file_prefix=\"bban_all\", save=True, load=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bban_df = pd.concat([bban_transformer_mamba_df, bban_all_df])\n",
    "bban_stats = grouped_rule_stats(bban_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## aNbN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "anbn_transformer_df, anbn_transformer_stats = get_sweep_stats(sweep_id=\"vn4yrcl8\", file_prefix=\"anbn_transformer\", save=True, load=False)\n",
    "anbn_lstm_df, anbn_lstm_stats = get_sweep_stats(sweep_id=\"t4yzbech\", file_prefix=\"anbn_lstm\", save=True, load=False)\n",
    "anbn_mamba_df, anbn_mamba_stats = get_sweep_stats(sweep_id=\"o27zaphz\", file_prefix=\"anbn_mamba\", save=True, load=False)\n",
    "anbn_no_transformer_df, anbn_no_transformer_stats = get_sweep_stats(sweep_id=\"nfrfpkqm\", file_prefix=\"anbn_no_transformer\", save=True, load=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "anbn_df = pd.concat([anbn_transformer_df, anbn_lstm_df, anbn_mamba_df, anbn_no_transformer_df])\n",
    "anbn_stats = grouped_rule_stats(anbn_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## aNbNcN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "anbncn_df, anbncn_stats = get_sweep_stats(sweep_id=\"6m1qb70e\", file_prefix=\"anbncn\", save=True, load=False)\n",
    "anbncn_lin_mamba_df, anbncn_lin_mamba_stats = get_sweep_stats(sweep_id=\"vtji6cx4\", file_prefix=\"anbncn_lin_mamba\", save=True, load=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "anbncn_df_merged = pd.concat([anbncn_df, anbncn_lin_mamba_df])\n",
    "anbncn_stats = grouped_rule_stats(anbncn_df_merged)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Matched brackets and parentheses"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dyck_df, dyck_stats = get_sweep_stats(sweep_id=\"eruf1l2q\", file_prefix=\"dyck\", save=True, load=False)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Human study"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "human_df = pd.read_excel(\"human_study.xlsx\")\n",
    "\n",
    "# fill nan with empty string\n",
    "human_df = human_df.fillna(\"\")\n",
    "\n",
    "# fill \"already completed\" with empty string\n",
    "human_df = human_df.replace(\"already completed\", \"\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prompts = list(human_df.columns[1:])\n",
    "# remove whitespace from beetween characters in the prompts\n",
    "prompts = [\"\".join(prompt.split()) for prompt in prompts]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# overwrite columns names in df\n",
    "human_df.columns = [\"timestamp\"] +prompts"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "A = A_token.item()\n",
    "B = B_token.item()\n",
    "OB = OPENING_BRACKET_token.item()\n",
    "OP = OPENING_PARENTHESIS_token.item()\n",
    "CB = CLOSING_BRACKET_token.item()\n",
    "CP = CLOSING_PARENTHESIS_token.item()\n",
    "\n",
    "def char2token(char):\n",
    "    char = char.upper()\n",
    "    if char == \"A\":\n",
    "        return A\n",
    "    elif char == \"B\":\n",
    "        return B\n",
    "    elif char == \"(\":\n",
    "        return OP\n",
    "    elif char == \")\":\n",
    "        return CP\n",
    "    elif char == \"[\":\n",
    "        return OB\n",
    "    elif char == \"]\":\n",
    "        return CB\n",
    "    else:\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# tokenize prompts\n",
    "prompts_tokenized = [[char2token(c) for c in prompt] for prompt in prompts]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenized_human_df = human_df.copy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for prompt, prompt_tokenized in zip(prompts, prompts_tokenized):\n",
    "\n",
    "    # get the column by prompt\n",
    "    col = human_df[prompt]\n",
    "    col_stripped = [\"\".join(prompt.split()) for prompt in col]\n",
    "    col_tokenized = [[char2token(c) for c in prompt] for prompt in col_stripped]\n",
    "\n",
    "    tokenized_human_df[prompt] = col_tokenized\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "anbn_r1_human = []\n",
    "anbn_r2_completion_human = []\n",
    "\n",
    "dyck_r1_human = []\n",
    "dyck_r2_completion_human = []\n",
    "\n",
    "ban_r1_human = []\n",
    "ban_r2_completion_human = []\n",
    "from llm_non_identifiability.data import check_same_number_as_bs, check_as_before_bs, check_even_number_of_as, check_begins_with_b, check_matched_brackets, check_matched_parentheses\n",
    "import torch\n",
    "\n",
    "for idx, (prompt, prompt_tokenized) in enumerate(zip(prompts, prompts_tokenized)):\n",
    "    # get the column by prompt\n",
    "    col = tokenized_human_df[prompt]\n",
    "\n",
    "    # iterate over the rows\n",
    "    for completion in col:\n",
    "\n",
    "        if None in completion:\n",
    "            continue\n",
    "\n",
    "        # add the tokenized prompt\n",
    "        completed_prompt = torch.tensor(prompt_tokenized.copy() + completion)\n",
    "        completion = torch.tensor(completion)\n",
    "        # print(completion)\n",
    "\n",
    "        if idx <= 4: # anbn\n",
    "            anbn_r1_human.append(check_same_number_as_bs(completed_prompt))\n",
    "            anbn_r2_completion_human.append(True if len(completion)==0 else check_as_before_bs(completion))\n",
    "        elif idx <=9    : # dyck\n",
    "            dyck_r1_human.append(check_matched_brackets(completed_prompt[2:]))\n",
    "            dyck_r2_completion_human.append(True if len(completion)==0 else check_matched_parentheses(completion))\n",
    "        else: # ban\n",
    "            ban_r1_human.append(check_even_number_of_as(completed_prompt))\n",
    "            ban_r2_completion_human.append(True if len(completion)==0 else check_begins_with_b(completion))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print accuracies\n",
    "print(f\"anbn R1: {np.mean(anbn_r1_human)}\")\n",
    "print(f\"anbn R2: {np.mean(anbn_r2_completion_human)}\")\n",
    "print(f\"dyck R1: {np.mean(dyck_r1_human)}\"\n",
    ")\n",
    "print(f\"dyck R2: {np.mean(dyck_r2_completion_human)}\")\n",
    "print(f\"ban R1: {np.mean(ban_r1_human)}\")\n",
    "print(f\"ban R2: {np.mean(ban_r2_completion_human)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "human_stats = {}\n",
    "human_stats[\"baN\"] = {\n",
    "    \"ood_rule_1\": np.mean(ban_r1_human),\n",
    "    \"ood_rule_2_completion\": np.mean(ban_r2_completion_human)\n",
    "}\n",
    "\n",
    "human_stats[\"aNbN\"] = {\n",
    "    \"ood_rule_1\": np.mean(anbn_r1_human),\n",
    "    \"ood_rule_2_completion\": np.mean(anbn_r2_completion_human)\n",
    "}\n",
    "\n",
    "human_stats[\"Dyck\"] = {\n",
    "    \"ood_rule_1\": np.mean(dyck_r1_human),\n",
    "    \"ood_rule_2_completion\": np.mean(dyck_r2_completion_human)\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Chance levels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "chance_stats = {}\n",
    "chance_stats[\"baN\"] = {\n",
    "    \"ood_rule_1\": 0.5,\n",
    "    \"ood_rule_2_completion\": 0.5\n",
    "}\n",
    "chance_stats[\"aNbN\"] = {\n",
    "    \"ood_rule_1\": 0.153,\n",
    "    \"ood_rule_2_completion\": 0.75\n",
    "}\n",
    "# chance_stats[\"Dyck\"] = {\n",
    "#     \"ood_rule_1\": 0.5,\n",
    "#     \"ood_rule_2_completion\": 0.5\n",
    "# }\n",
    "chance_stats[\"bbaN\"] = {\n",
    "    \"ood_rule_1\": 0.5,\n",
    "    \"ood_rule_2_completion\": 0.5\n",
    "}\n",
    "\n",
    "chance_stats[\"aNbNcN\"] = {\n",
    "    \"ood_rule_1\": 0.00945,\n",
    "    \"ood_rule_2_completion\": 0.5925\n",
    "}\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Plots"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## helper functions\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_loss_vs_rules(df, stats, cmap=\"coolwarm\", TICK_PADDING=2, LABELPAD=1, filename=None):\n",
    "\n",
    "    colors = {\n",
    "        \"transformer\": \"tab:blue\",\n",
    "        \"lstm\": \"tab:orange\",\n",
    "        \"linear\": \"tab:green\",\n",
    "        \"mamba\": \"tab:red\"\n",
    "        }\n",
    "\n",
    "\n",
    "    fig = plt.figure(figsize=figsizes.icml2022_full(nrows=1, ncols=2)['figure.figsize'])\n",
    "    ax = fig.add_subplot(121)\n",
    "    ax.grid(True, which=\"both\", ls=\"-.\")\n",
    "    ax.set_axisbelow(True)\n",
    "    for model in stats[\"val_loss\"].groups.keys():\n",
    "\n",
    "        im = ax.scatter(df[df.model == model].min_val_loss,\n",
    "                        100 * df[df.model == model].ood_rule_1_accuracy4min_val_loss, c=colors[model], label=model)\n",
    "    ax.set_ylabel(\"R1 \\%\", labelpad=LABELPAD)\n",
    "    ax.set_xlabel(\"Minimum test loss\", labelpad=LABELPAD)\n",
    "    # plt.legend()\n",
    "    ax.tick_params(axis='both', which='major', pad=TICK_PADDING)\n",
    "    ax = fig.add_subplot(122)\n",
    "    ax.grid(True, which=\"both\", ls=\"-.\")\n",
    "    ax.set_axisbelow(True)\n",
    "    for model in stats[\"val_loss\"].groups.keys():\n",
    "        im = ax.scatter(df[df.model == model].min_val_loss,\n",
    "                        100 * df[df.model == model].ood_rule_2_completion_accuracy4min_val_loss, c=colors[model], label=model)\n",
    "    ax.set_ylabel(\"R2 completion (\\%)\", labelpad=LABELPAD)\n",
    "    ax.set_xlabel(\"Minimum test loss\", labelpad=LABELPAD)\n",
    "    plt.legend(loc='lower center')\n",
    "    ax.tick_params(axis='both', which='major', pad=TICK_PADDING)\n",
    "\n",
    "    if filename is not None:\n",
    "        plt.savefig(f\"{filename}.svg\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## baN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_loss_vs_rules(ban_df, ban_stats, filename=\"ban_loss_vs_rules\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rule_stats2string_per_model(ban_stats)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## bbaN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_loss_vs_rules(bban_df, bban_stats, filename=\"bban_loss_vs_rules\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rule_stats2string_per_model(bban_stats)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## aNbN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_loss_vs_rules(anbn_df, anbn_stats, filename=\"anbn_loss_vs_rules\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rule_stats2string_per_model(anbn_stats)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## aNbNcN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_loss_vs_rules(anbncn_df, anbncn_stats, filename=\"anbncn_loss_vs_rules\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rule_stats2string_per_model(anbncn_stats)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Matched brackets and parentheses"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_loss_vs_rules(dyck_df, dyck_stats, filename=\"dyck_loss_vs_rules\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rule_stats2string_per_model(dyck_stats)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plot for all languages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TICK_PADDING = 2\n",
    "LABELPAD = 1\n",
    "cmap = \"coolwarm\"\n",
    "\n",
    "\n",
    "stats_dict = {\n",
    "    \"baN\": ban_stats,\n",
    "    \"bbaN\": bban_stats,\n",
    "    \"aNbN\": anbn_stats,\n",
    "    \"aNbNcN\": anbncn_stats,\n",
    "    \"Dyck\": dyck_stats,\n",
    "}\n",
    "\n",
    "colors = {\n",
    "        \"transformer\": \"tab:blue\",\n",
    "        \"lstm\": \"tab:orange\",\n",
    "        \"linear\": \"tab:green\",\n",
    "        \"mamba\": \"tab:red\",\n",
    "    \"human\" : \"black\",\n",
    "    # \"chance\": \"purple\"\n",
    "        }\n",
    "\n",
    "\n",
    "x_pos = list(range(len(stats_dict)))\n",
    "x_offsets = [-0.45, -0.3, -.15, .15, 0.3, .45]\n",
    "x_factor = 1/ len(stats_dict)\n",
    "\n",
    "fig = plt.figure(figsize=figsizes.neurips2022(nrows=1, ncols=2, tight_layout=True, rel_width=2)['figure.figsize'])\n",
    "\n",
    "ax = fig.add_subplot(121)\n",
    "# ax.grid(True, which=\"both\", ls=\"-.\")\n",
    "# ax.set_axisbelow(True)\n",
    "\n",
    "models =  colors.keys()\n",
    "for x, (grammar, stats) in enumerate(stats_dict.items()):\n",
    "\n",
    "    if grammar in chance_stats.keys():\n",
    "        chance = chance_stats[grammar][\"ood_rule_1\"]\n",
    "        ax.axhline(100*chance, xmin=x_factor*x, xmax=x_factor*(x+1),  color='black', linestyle='--', linewidth=0.5)\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "\n",
    "        if model == \"human\":\n",
    "            if grammar in human_stats.keys():\n",
    "                mean = human_stats[grammar][\"ood_rule_1\"]\n",
    "                std = 0\n",
    "            else:\n",
    "                continue\n",
    "        # elif model == \"chance\":\n",
    "        #     if grammar in chance_stats.keys():\n",
    "        #         mean = chance_stats[grammar][\"ood_rule_1\"]\n",
    "        #         std = 0\n",
    "        #     else:\n",
    "        #         continue\n",
    "        else:\n",
    "            if model not in stats[\"ood_rule_1\"].groups.keys():\n",
    "                continue\n",
    "            mean = stats[\"ood_rule_1\"].get_group(model).mean()\n",
    "            std = stats[\"ood_rule_1\"].get_group(model).std()\n",
    "\n",
    "\n",
    "        ax.errorbar(x + x_offsets[i], 100 * mean, yerr=10 * std, fmt='o', label=model, c=colors[model])\n",
    "\n",
    "\n",
    "\n",
    "    ax.axvline(x+0.5, color='black', linestyle='--', linewidth=0.5)\n",
    "\n",
    "\n",
    "ax.set_ylabel(\"R1 (\\%)\", labelpad=LABELPAD)\n",
    "\n",
    "# set xtick names\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(stats_dict.keys())\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "for x, (grammar, stats) in enumerate(stats_dict.items()):\n",
    "\n",
    "    if grammar in chance_stats.keys():\n",
    "        chance = chance_stats[grammar][\"ood_rule_2_completion\"]\n",
    "        ax2.axhline(100*chance, xmin=x_factor*x, xmax=x_factor*(x+1),  color='black', linestyle='--', linewidth=0.5)\n",
    "\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "\n",
    "        if model == \"human\":\n",
    "            if grammar in human_stats.keys():\n",
    "                mean = human_stats[grammar][\"ood_rule_2_completion\"]\n",
    "                std = 0\n",
    "            else:\n",
    "                continue\n",
    "        # elif model == \"chance\":\n",
    "        #     if grammar in chance_stats.keys():\n",
    "        #         mean = chance_stats[grammar][\"ood_rule_2_completion\"]\n",
    "        #         std = 0\n",
    "        #     else:\n",
    "        #         continue\n",
    "        else:\n",
    "            if model not in stats[\"ood_rule_2_completion\"].groups.keys():\n",
    "                continue\n",
    "            mean = stats[\"ood_rule_2_completion\"].get_group(model).mean()\n",
    "            std = stats[\"ood_rule_2_completion\"].get_group(model).std()\n",
    "\n",
    "        ax2.errorbar(x+x_offsets[i], 100*mean, yerr=10*std, fmt='o',c=colors[model], label = model)\n",
    "\n",
    "\n",
    "    ax2.axvline(x+0.5, color='black', linestyle='--', linewidth=0.5)\n",
    "\n",
    "\n",
    "# set xtick names\n",
    "ax2.set_xticks(x_pos)\n",
    "ax2.set_xticklabels(stats_dict.keys())\n",
    "ax2.set_ylabel(\"R2 completion (\\%)\", labelpad=LABELPAD)\n",
    "\n",
    "\n",
    "# plot legends, only one form each model with a dot as the symbol\n",
    "\n",
    "\n",
    "handles = [mlines.Line2D([], [], color=colors[model], marker='o', label=model.capitalize()) for model in models]\n",
    "ax2.legend(handles=handles, loc=\"center right\", bbox_to_anchor=(1.75, 0.5))#, loc='upper center',  ncol=4)\n",
    "\n",
    "\n",
    "\n",
    "# plt.legend()\n",
    "ax.tick_params(axis='both', which='major', pad=TICK_PADDING)\n",
    "\n",
    "plt.savefig(\"ood_summary.svg\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
