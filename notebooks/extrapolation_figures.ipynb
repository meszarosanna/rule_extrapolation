{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Setup and imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "from tueplots import bundles, figsizes\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "import sys\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "sys.path.insert(0, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from analysis import sweep2df, plot_typography, stats2string, RED, BLUE, rule_stats2string_per_model, grouped_rule_stats\n",
    "from rule_extrapolation.data import A_token, B_token, OPENING_BRACKET_token, OPENING_PARENTHESIS_token, CLOSING_BRACKET_token, CLOSING_PARENTHESIS_token"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "USETEX = True"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.rcParams.update(bundles.icml2022(usetex=USETEX))\n",
    "# plt.rcParams.update({\n",
    "#     'text.latex.preamble': [r'\\usepackage{amsfonts}', # mathbb\n",
    "#                             r'\\usepackage{amsmath}'] # boldsymbol\n",
    "# })"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_typography(usetex=USETEX, small=14, medium=14, big=18)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Constants\n",
    "ENTITY = \"causal-representation-learning\"\n",
    "PROJECT = \"rule_extrapolation\"\n",
    "\n",
    "# W&B API\n",
    "api = wandb.Api(timeout=200)\n",
    "runs = api.runs(ENTITY + \"/\" + PROJECT)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-05T17:49:00.415638Z",
     "start_time": "2024-08-05T17:48:58.478554Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data loading"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_sweep_stats(sweep_id, file_prefix, save=False, load=True, entity=ENTITY, project=PROJECT):\n",
    "    api = wandb.Api(timeout=400)\n",
    "    sweep = api.sweep(f\"{entity}/{project}/{sweep_id}\")\n",
    "    filename = f\"{file_prefix}_{sweep_id}\"\n",
    "    df,train_loss,val_loss,val_kl,val_accuracy,finised,ood_finised,sos_finised,r1,r2,grammatical,ood_r1,ood_r1_completion,ood_r2,ood_grammatical,sos_r1,sos_r2,sos_grammatical= sweep2df(sweep.runs, filename, save=save, load=load)\n",
    "    return df, grouped_rule_stats(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## baN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ban_no_transformer_df, _ = get_sweep_stats(sweep_id=\"frrbkgg0\", file_prefix=\"ban_no_transformer\", save=True, load=True)\n",
    "ban_transformer_df, _ = get_sweep_stats(sweep_id=\"9b9a0xtn\", file_prefix=\"ban_transformer\", save=True, load=True)\n",
    "ban_lstm_df, _ = get_sweep_stats(sweep_id=\"vzcozopj\", file_prefix=\"ban_lstm\", save=True, load=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ban_lin_df, _ = get_sweep_stats(sweep_id=\"8r2yb016\", file_prefix=\"ban_lin\", save=True, load=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# filter out linear models (incorrect logs)\n",
    "ban_no_transformer_df = ban_no_transformer_df[ban_no_transformer_df.model != \"linear\"]\n",
    "ban_transformer_df = ban_transformer_df[ban_transformer_df.model != \"linear\"]\n",
    "ban_lstm_df = ban_lstm_df[ban_lstm_df.model != \"linear\"]\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ban_df = pd.concat([ban_no_transformer_df, ban_transformer_df, ban_lstm_df, ban_lin_df])\n",
    "ban_stats = grouped_rule_stats(ban_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### sampling next token"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ban_sampling_df, ban_sampling_stats = get_sweep_stats(sweep_id=\"x3d2i6ja\", file_prefix=\"ban_sampling\", save=True, load=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## bbaN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bban_transformer_mamba_df, _ = get_sweep_stats(sweep_id=\"jjjtbh24\", file_prefix=\"bban_transformer_mamba\", save=True, load=True)\n",
    "bban_all_df, _ = get_sweep_stats(sweep_id=\"unc8bv65\", file_prefix=\"bban_all\", save=True, load=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bban_lin_df, _ = get_sweep_stats(sweep_id=\"dnpv6gpm\", file_prefix=\"bban_lin\", save=True, load=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# filter out linear models (incorrect logs)\n",
    "bban_transformer_mamba_df = bban_transformer_mamba_df[bban_transformer_mamba_df.model != \"linear\"]\n",
    "bban_all_df = bban_all_df[bban_all_df.model != \"linear\"]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bban_df = pd.concat([bban_transformer_mamba_df, bban_all_df, bban_lin_df])\n",
    "bban_stats = grouped_rule_stats(bban_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### sampling next token"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bban_sampling_df, bban_sampling_stats = get_sweep_stats(sweep_id=\"o9kfhvlu\", file_prefix=\"bban_sampling\", save=True, load=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## aNbN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "anbn_transformer_df, _ = get_sweep_stats(sweep_id=\"vn4yrcl8\", file_prefix=\"anbn_transformer\", save=True, load=True)\n",
    "anbn_lstm_df, _ = get_sweep_stats(sweep_id=\"t4yzbech\", file_prefix=\"anbn_lstm\", save=True, load=True)\n",
    "anbn_mamba_df, _ = get_sweep_stats(sweep_id=\"o27zaphz\", file_prefix=\"anbn_mamba\", save=True, load=True)\n",
    "anbn_no_transformer_df, _ = get_sweep_stats(sweep_id=\"nfrfpkqm\", file_prefix=\"anbn_no_transformer\", save=True, load=True)\n",
    "anbn_lin_df, _ = get_sweep_stats(sweep_id=\"8lijfxk2\", file_prefix=\"anbn_lin\", save=True, load=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# filter out linear models (incorrect logs)\n",
    "anbn_transformer_df = anbn_transformer_df[anbn_transformer_df.model != \"linear\"]\n",
    "anbn_lstm_df = anbn_lstm_df[anbn_lstm_df.model != \"linear\"]\n",
    "anbn_mamba_df = anbn_mamba_df[anbn_mamba_df.model != \"linear\"]\n",
    "anbn_no_transformer_df = anbn_no_transformer_df[anbn_no_transformer_df.model != \"linear\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "anbn_df = pd.concat([anbn_transformer_df, anbn_lstm_df, anbn_mamba_df, anbn_no_transformer_df, anbn_lin_df])\n",
    "anbn_stats = grouped_rule_stats(anbn_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### sampling next token"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Network error (HTTPError), entering retry loop.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Network error (HTTPError), entering retry loop.\n"
     ]
    },
    {
     "ename": "CommError",
     "evalue": "<Response [429]>",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mHTTPError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/wandb/apis/normalize.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     40\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 41\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     42\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mrequests\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mHTTPError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0merror\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/wandb/apis/public.py\u001B[0m in \u001B[0;36mhistory\u001B[0;34m(self, samples, keys, x_axis, pandas, stream)\u001B[0m\n\u001B[1;32m   2238\u001B[0m         \u001B[0;32melif\u001B[0m \u001B[0mkeys\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2239\u001B[0;31m             \u001B[0mlines\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_sampled_history\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkeys\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mkeys\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx_axis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mx_axis\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msamples\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msamples\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2240\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/wandb/apis/public.py\u001B[0m in \u001B[0;36m_sampled_history\u001B[0;34m(self, keys, x_axis, samples)\u001B[0m\n\u001B[1;32m   2138\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2139\u001B[0;31m         \u001B[0mresponse\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_exec\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mquery\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mspecs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mjson\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdumps\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mspec\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2140\u001B[0m         \u001B[0;31m# sampledHistory returns one list per spec, we only send one spec\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/wandb/apis/public.py\u001B[0m in \u001B[0;36m_exec\u001B[0;34m(self, query, **kwargs)\u001B[0m\n\u001B[1;32m   2124\u001B[0m         \u001B[0mvariables\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2125\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclient\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexecute\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mquery\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvariable_values\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mvariables\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2126\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/wandb/sdk/lib/retry.py\u001B[0m in \u001B[0;36mwrapped_fn\u001B[0;34m(*args, **kargs)\u001B[0m\n\u001B[1;32m    211\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mwrapped_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mAny\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkargs\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mAny\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mAny\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 212\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mretrier\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    213\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/wandb/sdk/lib/retry.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    130\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 131\u001B[0;31m                 \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    132\u001B[0m                 \u001B[0;31m# Only print resolved attempts once every minute\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/wandb/apis/public.py\u001B[0m in \u001B[0;36mexecute\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    216\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 217\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_client\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexecute\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    218\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mrequests\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexceptions\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mReadTimeout\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/wandb/vendor/gql-0.2.0/wandb_gql/client.py\u001B[0m in \u001B[0;36mexecute\u001B[0;34m(self, document, *args, **kwargs)\u001B[0m\n\u001B[1;32m     51\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 52\u001B[0;31m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_result\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdocument\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     53\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0merrors\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/wandb/vendor/gql-0.2.0/wandb_gql/client.py\u001B[0m in \u001B[0;36m_get_result\u001B[0;34m(self, document, *args, **kwargs)\u001B[0m\n\u001B[1;32m     59\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mretries\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 60\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtransport\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexecute\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdocument\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     61\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/wandb/sdk/lib/gql_request.py\u001B[0m in \u001B[0;36mexecute\u001B[0;34m(self, document, variable_values, timeout)\u001B[0m\n\u001B[1;32m     58\u001B[0m         \u001B[0mrequest\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msession\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpost\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0murl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mpost_args\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 59\u001B[0;31m         \u001B[0mrequest\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mraise_for_status\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     60\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/requests/models.py\u001B[0m in \u001B[0;36mraise_for_status\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    940\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mhttp_error_msg\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 941\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mHTTPError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhttp_error_msg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mresponse\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    942\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mHTTPError\u001B[0m: 429 Client Error: Too Many Requests for url: https://api.wandb.ai/graphql",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mCommError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/rb/d8k1n6bj4lg801y0yxz4jtbh0000gn/T/ipykernel_78903/232665051.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0manbn_sampling_df\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0manbn_sampling_stats\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_sweep_stats\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msweep_id\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"na40gehn\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfile_prefix\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"anbn_sampling\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msave\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mload\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/var/folders/rb/d8k1n6bj4lg801y0yxz4jtbh0000gn/T/ipykernel_78903/2207018134.py\u001B[0m in \u001B[0;36mget_sweep_stats\u001B[0;34m(sweep_id, file_prefix, save, load, entity, project)\u001B[0m\n\u001B[1;32m      3\u001B[0m     \u001B[0msweep\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mapi\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msweep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"{entity}/{project}/{sweep_id}\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m     \u001B[0mfilename\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34mf\"{file_prefix}_{sweep_id}\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m     \u001B[0mdf\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mtrain_loss\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mval_loss\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mval_kl\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mval_accuracy\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mfinised\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mood_finised\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0msos_finised\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mr1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mr2\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mgrammatical\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mood_r1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mood_r1_completion\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mood_r2\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mood_grammatical\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0msos_r1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0msos_r2\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0msos_grammatical\u001B[0m\u001B[0;34m=\u001B[0m \u001B[0msweep2df\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msweep\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mruns\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfilename\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msave\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msave\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mload\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      6\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mdf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgrouped_rule_stats\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/GitHub/rule_extrapolation/notebooks/./analysis.py\u001B[0m in \u001B[0;36msweep2df\u001B[0;34m(sweep_runs, filename, save, load)\u001B[0m\n\u001B[1;32m    206\u001B[0m                 )\n\u001B[1;32m    207\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 208\u001B[0;31m                 \u001B[0mval_accuracy_history\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mrun\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhistory\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkeys\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34mf\"Val/accuracy\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    209\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    210\u001B[0m                 max_val_accuracy_step, max_val_accuracy = (\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/wandb/apis/normalize.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     49\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     50\u001B[0m                 \u001B[0mmessage\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0merror\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mresponse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 51\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mCommError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmessage\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0merror\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     52\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mRetryError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     53\u001B[0m             if (\n",
      "\u001B[0;31mCommError\u001B[0m: <Response [429]>"
     ]
    }
   ],
   "source": [
    "anbn_sampling_df, anbn_sampling_stats = get_sweep_stats(sweep_id=\"na40gehn\", file_prefix=\"anbn_sampling\", save=True, load=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-05T17:49:52.186082Z",
     "start_time": "2024-08-05T17:49:05.760759Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## aNbNcN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "anbncn_df, _ = get_sweep_stats(sweep_id=\"6m1qb70e\", file_prefix=\"anbncn\", save=True, load=True)\n",
    "anbncn_lin_mamba_df, _ = get_sweep_stats(sweep_id=\"vtji6cx4\", file_prefix=\"anbncn_lin_mamba\", save=True, load=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "anbncn_lin_df, _ = get_sweep_stats(sweep_id=\"p135j0eg\", file_prefix=\"anbncn_lin\", save=True, load=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "anbncn_df = anbncn_df[anbncn_df.model != \"linear\"]\n",
    "anbncn_lin_mamba_df = anbncn_lin_mamba_df[anbncn_lin_mamba_df.model != \"linear\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "anbncn_df_merged = pd.concat([anbncn_df, anbncn_lin_mamba_df, anbncn_lin_df])\n",
    "anbncn_stats = grouped_rule_stats(anbncn_df_merged)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### sampling next token"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "anbncn_sampling_df, anbncn_sampling_stats = get_sweep_stats(sweep_id=\"ha3dnqdt\", file_prefix=\"anbncn_sampling\", save=True, load=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dyck"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dyck_df, _ = get_sweep_stats(sweep_id=\"eruf1l2q\", file_prefix=\"dyck\", save=True, load=True)\n",
    "dyck_df = dyck_df[dyck_df.model != \"linear\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dyck_lin_df, _ = get_sweep_stats(sweep_id=\"gw4fwwsr\", file_prefix=\"dyck_lin\", save=True, load=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dyck_df = pd.concat([dyck_df, dyck_lin_df])\n",
    "dyck_stats = grouped_rule_stats(dyck_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### sampling next token"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dyck_sampling_df, dyck_sampling_stats = get_sweep_stats(sweep_id=\"i6um5idm\", file_prefix=\"dyck_sampling\", save=True, load=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Context-sensitive Dyck"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cs_dyck_df, _ = get_sweep_stats(sweep_id=\"6dunl50v\", file_prefix=\"cs_dyck\", save=True, load=True)\n",
    "cs_dyck_lstm_df, _ = get_sweep_stats(sweep_id=\"c9vbbut5\", file_prefix=\"cs_dyck_lstm\", save=True, load=True)\n",
    "\n",
    "cs_dyck_df_merged = pd.concat([cs_dyck_df, cs_dyck_lstm_df])\n",
    "cs_dyck_stats = grouped_rule_stats(cs_dyck_df_merged)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Sampling next token"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cs_dyck_sampling_df, cs_dyck_sampling_stats = get_sweep_stats(sweep_id=\"81d37nzc\", file_prefix=\"cs_dyck_sampling\", save=True, load=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## xLSTM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "xlstm_ban_df, xlstm_ban_stats = get_sweep_stats(sweep_id=\"x5xyd945\", file_prefix=\"xlstm_ban\", save=True, load=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "xlstm_bban_df, xlstm_bban_stats = get_sweep_stats(sweep_id=\"ym11gp19\", file_prefix=\"xlstm_bban\", save=True, load=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "xlstm_anbn_df, xlstm_anbn_stats = get_sweep_stats(sweep_id=\"bz6anbf5\", file_prefix=\"xlstm_anbn\", save=True, load=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "xlstm_anbncn_df, xlstm_anbncn_stats = get_sweep_stats(sweep_id=\"2jlvxifc\", file_prefix=\"xlstm_anbncn\", save=True, load=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "xlstm_dyck_df, xlstm_dyck_stats = get_sweep_stats(sweep_id=\"5cmjvijy\", file_prefix=\"xlstm_dyck\", save=True, load=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "xlstm_cs_dyck_df, xlstm_cs_dyck_stats = get_sweep_stats(sweep_id=\"z29t7s6e\", file_prefix=\"xlstm_cs_dyck\", save=True, load=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameter search"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hyper_ban_df, hyper_ban_stats = get_sweep_stats(sweep_id=\"nza9ka3b\", file_prefix=\"hyper_ban\", save=True, load=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hyper_bban_df, hyper_bban_stats = get_sweep_stats(sweep_id=\"6fpd9uqg\", file_prefix=\"hyper_bban\", save=True, load=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hyper_anbn_df, hyper_anbn_stats = get_sweep_stats(sweep_id=\"amsk1ba7\", file_prefix=\"hyper_anbn\", save=True, load=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hyper_anbncn_df, hyper_anbncn_stats = get_sweep_stats(sweep_id=\"5prt0zmv\", file_prefix=\"hyper_anbncn\", save=True, load=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hyper_dyck_df, hyper_dyck_stats = get_sweep_stats(sweep_id=\"2r7j2cfm\", file_prefix=\"hyper_dyck\", save=True, load=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hyper_cs_dyck_df, hyper_cs_dyck_stats = get_sweep_stats(sweep_id=\"nakt9wnj\", file_prefix=\"hyper_cs_dyck\", save=True, load=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Transformer size ablation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "transformer_size_ban_df, transformer_size_ban_stats = get_sweep_stats(sweep_id=\"r6gelh9k\", file_prefix=\"transformer_size_ban\", save=True, load=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "transformer_size_bban_df, transformer_size_bban_stats = get_sweep_stats(sweep_id=\"53nmwmq1\", file_prefix=\"transformer_size_bban\", save=True, load=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "transformer_size_anbn_df, transformer_size_anbn_stats = get_sweep_stats(sweep_id=\"ddfjwbsl\", file_prefix=\"transformer_size_anbn\", save=True, load=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "transformer_size_anbncn_df, transformer_size_anbncn_stats = get_sweep_stats(sweep_id=\"yv9ajwdv\", file_prefix=\"transformer_size_anbncn\", save=True, load=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "transformer_size_dyck_df, transformer_size_dyck_stats = get_sweep_stats(sweep_id=\"v672gglg\", file_prefix=\"transformer_size_dyck\", save=True, load=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Human study"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "human_df = pd.read_excel(\"human_study.xlsx\")\n",
    "\n",
    "# fill nan with empty string\n",
    "human_df = human_df.fillna(\"\")\n",
    "\n",
    "# fill \"already completed\" with empty string\n",
    "human_df = human_df.replace(\"already completed\", \"\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prompts = list(human_df.columns[1:])\n",
    "# remove whitespace from beetween characters in the prompts\n",
    "prompts = [\"\".join(prompt.split()) for prompt in prompts]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# overwrite columns names in df\n",
    "human_df.columns = [\"timestamp\"] +prompts"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "A = A_token.item()\n",
    "B = B_token.item()\n",
    "OB = OPENING_BRACKET_token.item()\n",
    "OP = OPENING_PARENTHESIS_token.item()\n",
    "CB = CLOSING_BRACKET_token.item()\n",
    "CP = CLOSING_PARENTHESIS_token.item()\n",
    "\n",
    "def char2token(char):\n",
    "    char = char.upper()\n",
    "    if char == \"A\":\n",
    "        return A\n",
    "    elif char == \"B\":\n",
    "        return B\n",
    "    elif char == \"(\":\n",
    "        return OP\n",
    "    elif char == \")\":\n",
    "        return CP\n",
    "    elif char == \"[\":\n",
    "        return OB\n",
    "    elif char == \"]\":\n",
    "        return CB\n",
    "    else:\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# tokenize prompts\n",
    "prompts_tokenized = [[char2token(c) for c in prompt] for prompt in prompts]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenized_human_df = human_df.copy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for prompt, prompt_tokenized in zip(prompts, prompts_tokenized):\n",
    "\n",
    "    # get the column by prompt\n",
    "    col = human_df[prompt]\n",
    "    col_stripped = [\"\".join(prompt.split()) for prompt in col]\n",
    "    col_tokenized = [[char2token(c) for c in prompt] for prompt in col_stripped]\n",
    "\n",
    "    tokenized_human_df[prompt] = col_tokenized\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "anbn_r1_human = []\n",
    "anbn_r2_completion_human = []\n",
    "\n",
    "dyck_r1_human = []\n",
    "dyck_r2_completion_human = []\n",
    "\n",
    "ban_r1_human = []\n",
    "ban_r2_completion_human = []\n",
    "from llm_non_identifiability.data import check_same_number_as_bs, check_as_before_bs, check_even_number_of_as, check_begins_with_b, check_matched_brackets, check_matched_parentheses\n",
    "import torch\n",
    "\n",
    "for idx, (prompt, prompt_tokenized) in enumerate(zip(prompts, prompts_tokenized)):\n",
    "    # get the column by prompt\n",
    "    col = tokenized_human_df[prompt]\n",
    "\n",
    "    # iterate over the rows\n",
    "    for completion in col:\n",
    "\n",
    "        if None in completion:\n",
    "            continue\n",
    "\n",
    "        # add the tokenized prompt\n",
    "        completed_prompt = torch.tensor(prompt_tokenized.copy() + completion)\n",
    "        completion = torch.tensor(completion)\n",
    "        # print(completion)\n",
    "\n",
    "        if idx < 4: # anbn, idx 4 is in-distribution\n",
    "            anbn_r1_human.append(check_same_number_as_bs(completed_prompt))\n",
    "            anbn_r2_completion_human.append(True if len(completion)==0 else check_as_before_bs(completion))\n",
    "        elif 4 < idx <=9    : # dyck\n",
    "            dyck_r1_human.append(check_matched_brackets(completed_prompt[2:]))\n",
    "            dyck_r2_completion_human.append(True if len(completion)==0 else check_matched_parentheses(completion))\n",
    "        else: # ban\n",
    "            ban_r1_human.append(check_even_number_of_as(completed_prompt))\n",
    "            ban_r2_completion_human.append(True if len(completion)==0 else check_begins_with_b(completion))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print accuracies\n",
    "print(f\"anbn R1: {np.mean(anbn_r1_human)}\")\n",
    "print(f\"anbn R2: {np.mean(anbn_r2_completion_human)}\")\n",
    "print(f\"dyck R1: {np.mean(dyck_r1_human)}\"\n",
    ")\n",
    "print(f\"dyck R2: {np.mean(dyck_r2_completion_human)}\")\n",
    "print(f\"ban R1: {np.mean(ban_r1_human)}\")\n",
    "print(f\"ban R2: {np.mean(ban_r2_completion_human)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "human_stats = {}\n",
    "human_stats[\"baN\"] = {\n",
    "    \"ood_rule_1\": np.mean(ban_r1_human),\n",
    "    \"ood_rule_2_completion\": np.mean(ban_r2_completion_human)\n",
    "}\n",
    "\n",
    "human_stats[\"aNbN\"] = {\n",
    "    \"ood_rule_1\": np.mean(anbn_r1_human),\n",
    "    \"ood_rule_2_completion\": np.mean(anbn_r2_completion_human)\n",
    "}\n",
    "\n",
    "# human_stats[\"Dyck\"] = {\n",
    "#     \"ood_rule_1\": np.mean(dyck_r1_human),\n",
    "#     \"ood_rule_2_completion\": np.mean(dyck_r2_completion_human)\n",
    "# }"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Chance levels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "chance_stats = {}\n",
    "chance_stats[\"baN\"] = {\n",
    "    \"ood_rule_1\": 0.5,\n",
    "    \"ood_rule_2_completion\": 1./3\n",
    "}\n",
    "\n",
    "chance_stats[\"bbaN\"] = {\n",
    "    \"ood_rule_1\": 0.5,\n",
    "    \"ood_rule_2_completion\": 0.75\n",
    "}\n",
    "\n",
    "\n",
    "chance_stats[\"aNbN\"] = {\n",
    "    \"ood_rule_1\": 0.154,\n",
    "    \"ood_rule_2_completion\": 0.4445\n",
    "}\n",
    "chance_stats[\"Dyck\"] = {\n",
    "    \"ood_rule_1\": 0.1273,\n",
    "    \"ood_rule_2_completion\": 0.382\n",
    "}\n",
    "\n",
    "chance_stats[\"aNbNcN\"] = {\n",
    "    \"ood_rule_1\": 0.00334,\n",
    "    \"ood_rule_2_completion\": 0.5925\n",
    "}\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Plots"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## helper functions\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_loss_vs_rules(df, stats, cmap=\"coolwarm\", TICK_PADDING=2, LABELPAD=1, filename=None):\n",
    "\n",
    "    colors = {\n",
    "        \"transformer\": \"tab:blue\",\n",
    "        \"lstm\": \"tab:orange\",\n",
    "        \"linear\": \"tab:green\",\n",
    "        \"mamba\": \"tab:red\"\n",
    "        }\n",
    "\n",
    "\n",
    "    fig = plt.figure(figsize=figsizes.icml2022_full(nrows=1, ncols=2)['figure.figsize'])\n",
    "    ax = fig.add_subplot(121)\n",
    "    ax.grid(True, which=\"both\", ls=\"-.\")\n",
    "    ax.set_axisbelow(True)\n",
    "    for model in stats[\"val_loss\"].groups.keys():\n",
    "\n",
    "        im = ax.scatter(df[df.model == model].min_val_loss,\n",
    "                        100 * df[df.model == model].ood_rule_1_accuracy4min_val_loss, c=colors[model], label=model.capitalize() if model != \"lstm\" else model.upper())\n",
    "    ax.set_ylabel(\"R1 \\%\", labelpad=LABELPAD)\n",
    "    ax.set_xlabel(\"Minimum test loss\", labelpad=LABELPAD)\n",
    "    # plt.legend()\n",
    "    ax.tick_params(axis='both', which='major', pad=TICK_PADDING)\n",
    "    ax = fig.add_subplot(122)\n",
    "    ax.grid(True, which=\"both\", ls=\"-.\")\n",
    "    ax.set_axisbelow(True)\n",
    "    for model in stats[\"val_loss\"].groups.keys():\n",
    "        im = ax.scatter(df[df.model == model].min_val_loss,\n",
    "                        100 * df[df.model == model].ood_rule_2_completion_accuracy4min_val_loss, c=colors[model], label=model.capitalize() if model != \"lstm\" else model.upper())\n",
    "    ax.set_ylabel(\"R2 completion (\\%)\", labelpad=LABELPAD)\n",
    "    ax.set_xlabel(\"Minimum test loss\", labelpad=LABELPAD)\n",
    "    plt.legend(loc=\"center right\", bbox_to_anchor=(1.75, 0.5))\n",
    "    ax.tick_params(axis='both', which='major', pad=TICK_PADDING)\n",
    "\n",
    "    if filename is not None:\n",
    "        plt.savefig(f\"{filename}.svg\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## baN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_loss_vs_rules(ban_df, ban_stats, filename=\"ban_loss_vs_rules\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rule_stats2string_per_model(ban_stats, include_r2=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## bbaN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_loss_vs_rules(bban_df, bban_stats, filename=\"bban_loss_vs_rules\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rule_stats2string_per_model(bban_stats)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## aNbN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_loss_vs_rules(anbn_df, anbn_stats, filename=\"anbn_loss_vs_rules\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rule_stats2string_per_model(anbn_stats)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## aNbNcN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_loss_vs_rules(anbncn_df, anbncn_stats, filename=\"anbncn_loss_vs_rules\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rule_stats2string_per_model(anbncn_stats)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dyck"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_loss_vs_rules(dyck_df, dyck_stats, filename=\"dyck_loss_vs_rules\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rule_stats2string_per_model(dyck_stats)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plot for all languages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TICK_PADDING = 2\n",
    "LABELPAD = 1\n",
    "cmap = \"coolwarm\"\n",
    "\n",
    "\n",
    "stats_dict = {\n",
    "    \"baN\": ban_stats,\n",
    "    \"bbaN\": bban_stats,\n",
    "    \"aNbN\": anbn_stats,\n",
    "    \"aNbNcN\": anbncn_stats,\n",
    "    \"Dyck\": dyck_stats,\n",
    "}\n",
    "\n",
    "labels = [\n",
    "    r\"$b\\alpha$\",\n",
    "    r\"$b^na^{2m}$\",\n",
    "    r\"$a^nb^n$\",\n",
    "    r\"$a^nb^nc^n$\",\n",
    "    \"Dyck\"\n",
    "]\n",
    "\n",
    "colors = {\n",
    "        \"transformer\": \"tab:blue\",\n",
    "        \"lstm\": \"tab:orange\",\n",
    "        \"linear\": \"tab:green\",\n",
    "        \"mamba\": \"tab:red\",\n",
    "    # \"human\" : \"black\",\n",
    "    # \"chance\": \"purple\"\n",
    "        }\n",
    "\n",
    "\n",
    "x_pos = list(range(len(stats_dict)))\n",
    "x_offsets = [-0.3, -0.1, .1, 0.3]\n",
    "x_factor = 1/ len(stats_dict)\n",
    "width = 0.35\n",
    "x_stretch = 3\n",
    "x_pos = [x*x_stretch for x in x_pos]\n",
    "\n",
    "fig = plt.figure(figsize=figsizes.neurips2022(nrows=1, ncols=3, tight_layout=True, rel_width=2)['figure.figsize'])\n",
    "\n",
    "ax = fig.add_subplot(121)\n",
    "# ax.grid(True, which=\"both\", ls=\"-.\")\n",
    "# ax.set_axisbelow(True)\n",
    "\n",
    "models =  colors.keys()\n",
    "for x, (grammar, stats) in enumerate(stats_dict.items()):\n",
    "    #\n",
    "    if grammar in chance_stats.keys():\n",
    "        chance = chance_stats[grammar][\"ood_rule_1\"]\n",
    "        rectangle = matplotlib.patches.Rectangle((x_stretch*(x-0.5),0), width=x_stretch, height=100*chance, color='gray', alpha=.35)\n",
    "        ax.add_patch(rectangle)\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "\n",
    "        # if model == \"human\":\n",
    "        #     if grammar in human_stats.keys():\n",
    "        #         mean = human_stats[grammar][\"ood_rule_1\"]\n",
    "        #         std = 0\n",
    "        #     else:\n",
    "        #         continue\n",
    "        # else:\n",
    "        if model not in stats[\"ood_rule_1\"].groups.keys():\n",
    "            continue\n",
    "        mean = stats[\"ood_rule_1\"].get_group(model).mean()\n",
    "        std = stats[\"ood_rule_1\"].get_group(model).std()\n",
    "\n",
    "\n",
    "\n",
    "        if mean < 0.01:\n",
    "            ax.errorbar(x_stretch*(x + x_offsets[i]), 100 * mean, yerr=10 * std, fmt=\"o\",  label=model, c=colors[model])\n",
    "        else:\n",
    "            ax.bar(x_stretch*(x + x_offsets[i]), 100 * mean, yerr=10 * std, width=width,  label=model, color=colors[model])\n",
    "\n",
    "\n",
    "    ax.axvline(x_stretch*(x+0.5), color='black', linestyle='--', linewidth=0.5)\n",
    "\n",
    "\n",
    "ax.set_ylabel(\"R1 (\\%)\", labelpad=LABELPAD)\n",
    "\n",
    "# set xtick names\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_xlim(x_stretch*x_offsets[0]-.35,x_stretch*(len(stats_dict)-1+x_offsets[-1])+.25)\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "for x, (grammar, stats) in enumerate(stats_dict.items()):\n",
    "\n",
    "    if grammar in chance_stats.keys():\n",
    "        chance = chance_stats[grammar][\"ood_rule_2_completion\"]\n",
    "        # ax2.plot([x_stretch*(x-0.5), x_stretch*(x+0.5)], [100*chance,100*chance], c=\"black\", linewidth=0.65)\n",
    "        rectangle = matplotlib.patches.Rectangle((x_stretch*(x-0.5),0), width=x_stretch, height=100*chance, color='gray', alpha=0.35)\n",
    "        ax2.add_patch(rectangle)\n",
    "\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "\n",
    "        # if model == \"human\":\n",
    "        #     if grammar in human_stats.keys():\n",
    "        #         mean = human_stats[grammar][\"ood_rule_2_completion\"]\n",
    "        #         std = 0\n",
    "        #     else:\n",
    "        #         continue\n",
    "        # else:\n",
    "        if model not in stats[\"ood_rule_2_completion\"].groups.keys():\n",
    "            continue\n",
    "        mean = stats[\"ood_rule_2_completion\"].get_group(model).mean()\n",
    "        std = stats[\"ood_rule_2_completion\"].get_group(model).std()\n",
    "\n",
    "        # ax2.errorbar(x+x_offsets[i], 100*mean, yerr=10*std, fmt='o',c=colors[model], label = model)\n",
    "        if mean < 0.01:\n",
    "            ax2.errorbar(x_stretch*(x + x_offsets[i]), 100 * mean, yerr=10 * std, fmt=\"o\",  label=model, c=colors[model])\n",
    "        else:\n",
    "            ax2.bar(x_stretch*(x + x_offsets[i]), 100 * mean, yerr=10 * std, width=width,  label=model, color=colors[model])\n",
    "\n",
    "\n",
    "    ax2.axvline(x_stretch*(x+0.5), color='black', linestyle='--', linewidth=0.5)\n",
    "\n",
    "\n",
    "# set xtick names\n",
    "ax2.set_xticks(x_pos)\n",
    "ax2.set_xticklabels(labels)\n",
    "ax2.set_ylabel(\"R2 completion (\\%)\", labelpad=LABELPAD)\n",
    "ax2.set_xlim(x_stretch*x_offsets[0]-.35,x_stretch*(len(stats_dict)-1+x_offsets[-1])+.25)\n",
    "\n",
    "handles = [mlines.Line2D([], [], color=colors[model], marker='o', label=model.capitalize() if model != \"lstm\" else model.upper()) for model in models] + [matplotlib.patches.Patch(color='gray', alpha=0.35, label='Chance-level')]\n",
    "ax2.legend(handles=handles, loc=\"center right\", bbox_to_anchor=(1.5, 0.5))#, loc='upper center',  ncol=4)\n",
    "\n",
    "\n",
    "\n",
    "# plt.legend()\n",
    "ax.tick_params(axis='both', which='major', pad=TICK_PADDING)\n",
    "\n",
    "plt.savefig(\"ood_summary.svg\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "anbncn_stats[\"ood_rule_1\"].get_group(\"linear\").mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
