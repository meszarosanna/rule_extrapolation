{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Setup and imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "from tueplots import bundles, figsizes\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "import sys\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "sys.path.insert(0, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from analysis import sweep2df, plot_typography, stats2string, RED, BLUE, rule_stats2string_per_model, grouped_rule_stats\n",
    "from rule_extrapolation.data import A_token, B_token, OPENING_BRACKET_token, OPENING_PARENTHESIS_token, CLOSING_BRACKET_token, CLOSING_PARENTHESIS_token"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "USETEX = True"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.rcParams.update(bundles.icml2022(usetex=USETEX))\n",
    "# plt.rcParams.update({\n",
    "#     'text.latex.preamble': [r'\\usepackage{amsfonts}', # mathbb\n",
    "#                             r'\\usepackage{amsmath}'] # boldsymbol\n",
    "# })"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_typography(usetex=USETEX, small=14, medium=14, big=18)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Constants\n",
    "ENTITY = \"causal-representation-learning\"\n",
    "PROJECT = \"rule_extrapolation\"\n",
    "\n",
    "# W&B API\n",
    "api = wandb.Api(timeout=400)\n",
    "runs = api.runs(ENTITY + \"/\" + PROJECT)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data loading"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_sweep_stats(sweep_id, file_prefix, save=False, load=True, entity=ENTITY, project=PROJECT, pick_max=True):\n",
    "    api = wandb.Api(timeout=400)\n",
    "    sweep = api.sweep(f\"{entity}/{project}/{sweep_id}\")\n",
    "    filename = f\"{file_prefix}_{sweep_id}\"\n",
    "    df,train_loss,val_loss,val_kl,val_accuracy,finised,ood_finised,sos_finised,r1,r3, r2,grammatical,ood_r1, ood_r3, ood_r1_completion,ood_r2,ood_grammatical,sos_r1,sos_r3, sos_r2,sos_grammatical= sweep2df(sweep.runs, filename, save=save, load=load, pick_max=pick_max)\n",
    "    return df, grouped_rule_stats(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## baN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ban_no_transformer_df, _ = get_sweep_stats(sweep_id=\"frrbkgg0\", file_prefix=\"ban_no_transformer\", save=True, load=True)\n",
    "ban_transformer_df, _ = get_sweep_stats(sweep_id=\"9b9a0xtn\", file_prefix=\"ban_transformer\", save=True, load=True)\n",
    "ban_lstm_df, _ = get_sweep_stats(sweep_id=\"vzcozopj\", file_prefix=\"ban_lstm\", save=True, load=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ban_lin_df, _ = get_sweep_stats(sweep_id=\"8r2yb016\", file_prefix=\"ban_lin\", save=True, load=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# filter out linear models (incorrect logs)\n",
    "ban_no_transformer_df = ban_no_transformer_df[ban_no_transformer_df.model != \"linear\"]\n",
    "ban_transformer_df = ban_transformer_df[ban_transformer_df.model != \"linear\"]\n",
    "ban_lstm_df = ban_lstm_df[ban_lstm_df.model != \"linear\"]\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ban_df = pd.concat([ban_no_transformer_df, ban_transformer_df, ban_lstm_df, ban_lin_df])\n",
    "ban_stats = grouped_rule_stats(ban_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### sampling next token"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ban_sampling_df, ban_sampling_stats = get_sweep_stats(sweep_id=\"x3d2i6ja\", file_prefix=\"ban_sampling\", save=True, load=True, pick_max=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## bbaN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bban_transformer_mamba_df, _ = get_sweep_stats(sweep_id=\"jjjtbh24\", file_prefix=\"bban_transformer_mamba\", save=True, load=True)\n",
    "bban_all_df, _ = get_sweep_stats(sweep_id=\"unc8bv65\", file_prefix=\"bban_all\", save=True, load=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bban_lin_df, _ = get_sweep_stats(sweep_id=\"dnpv6gpm\", file_prefix=\"bban_lin\", save=True, load=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# filter out linear models (incorrect logs)\n",
    "bban_transformer_mamba_df = bban_transformer_mamba_df[bban_transformer_mamba_df.model != \"linear\"]\n",
    "bban_all_df = bban_all_df[bban_all_df.model != \"linear\"]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bban_df = pd.concat([bban_transformer_mamba_df, bban_all_df, bban_lin_df])\n",
    "bban_stats = grouped_rule_stats(bban_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### sampling next token"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bban_sampling_df, bban_sampling_stats = get_sweep_stats(sweep_id=\"o9kfhvlu\", file_prefix=\"bban_sampling\", save=True, load=True,  pick_max=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## aNbN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "anbn_transformer_df, _ = get_sweep_stats(sweep_id=\"vn4yrcl8\", file_prefix=\"anbn_transformer\", save=True, load=True)\n",
    "anbn_lstm_df, _ = get_sweep_stats(sweep_id=\"t4yzbech\", file_prefix=\"anbn_lstm\", save=True, load=True)\n",
    "anbn_mamba_df, _ = get_sweep_stats(sweep_id=\"o27zaphz\", file_prefix=\"anbn_mamba\", save=True, load=True)\n",
    "anbn_no_transformer_df, _ = get_sweep_stats(sweep_id=\"nfrfpkqm\", file_prefix=\"anbn_no_transformer\", save=True, load=True)\n",
    "anbn_lin_df, _ = get_sweep_stats(sweep_id=\"8lijfxk2\", file_prefix=\"anbn_lin\", save=True, load=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# filter out linear models (incorrect logs)\n",
    "anbn_transformer_df = anbn_transformer_df[anbn_transformer_df.model != \"linear\"]\n",
    "anbn_lstm_df = anbn_lstm_df[anbn_lstm_df.model != \"linear\"]\n",
    "anbn_mamba_df = anbn_mamba_df[anbn_mamba_df.model != \"linear\"]\n",
    "anbn_no_transformer_df = anbn_no_transformer_df[anbn_no_transformer_df.model != \"linear\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "anbn_df = pd.concat([anbn_transformer_df, anbn_lstm_df, anbn_mamba_df, anbn_no_transformer_df, anbn_lin_df])\n",
    "anbn_stats = grouped_rule_stats(anbn_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### sampling next token"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "anbn_sampling_df, anbn_sampling_stats = get_sweep_stats(sweep_id=\"na40gehn\", file_prefix=\"anbn_sampling\", save=True, load=True,  pick_max=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### aNbN parity"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "anbn_parity_df, anbn_parity_stats = get_sweep_stats(sweep_id=\"9qz5sdef\", file_prefix=\"anbn_parity\", save=True, load=False,  pick_max=True)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## aNbNcN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "anbncn_df, _ = get_sweep_stats(sweep_id=\"6m1qb70e\", file_prefix=\"anbncn\", save=True, load=True)\n",
    "anbncn_lin_mamba_df, _ = get_sweep_stats(sweep_id=\"vtji6cx4\", file_prefix=\"anbncn_lin_mamba\", save=True, load=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "anbncn_lin_df, _ = get_sweep_stats(sweep_id=\"p135j0eg\", file_prefix=\"anbncn_lin\", save=True, load=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "anbncn_df = anbncn_df[anbncn_df.model != \"linear\"]\n",
    "anbncn_lin_mamba_df = anbncn_lin_mamba_df[anbncn_lin_mamba_df.model != \"linear\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "anbncn_df_merged = pd.concat([anbncn_df, anbncn_lin_mamba_df, anbncn_lin_df])\n",
    "anbncn_stats = grouped_rule_stats(anbncn_df_merged)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### sampling next token"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "anbncn_sampling_df, anbncn_sampling_stats = get_sweep_stats(sweep_id=\"ha3dnqdt\", file_prefix=\"anbncn_sampling\", save=True, load=True,  pick_max=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dyck"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dyck_df, _ = get_sweep_stats(sweep_id=\"eruf1l2q\", file_prefix=\"dyck\", save=True, load=True)\n",
    "dyck_df = dyck_df[dyck_df.model != \"linear\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dyck_lin_df, _ = get_sweep_stats(sweep_id=\"gw4fwwsr\", file_prefix=\"dyck_lin\", save=True, load=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dyck_df = pd.concat([dyck_df, dyck_lin_df])\n",
    "dyck_stats = grouped_rule_stats(dyck_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### sampling next token"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dyck_sampling_df, dyck_sampling_stats = get_sweep_stats(sweep_id=\"i6um5idm\", file_prefix=\"dyck_sampling\", save=True, load=True,  pick_max=True)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Context-sensitive Dyck"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cs_dyck_df, _ = get_sweep_stats(sweep_id=\"6dunl50v\", file_prefix=\"cs_dyck\", save=True, load=True)\n",
    "cs_dyck_lstm_df, _ = get_sweep_stats(sweep_id=\"c9vbbut5\", file_prefix=\"cs_dyck_lstm\", save=True, load=True)\n",
    "\n",
    "cs_dyck_df_merged = pd.concat([cs_dyck_df, cs_dyck_lstm_df])\n",
    "cs_dyck_stats = grouped_rule_stats(cs_dyck_df_merged)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Sampling next token"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cs_dyck_sampling_df, cs_dyck_sampling_stats = get_sweep_stats(sweep_id=\"81d37nzc\", file_prefix=\"cs_dyck_sampling\", save=True, load=True,  pick_max=True)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## xLSTM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "xlstm_ban_df, xlstm_ban_stats = get_sweep_stats(sweep_id=\"bg56nj7q\", file_prefix=\"xlstm_ban\", save=True, load=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "xlstm_bban_df, xlstm_bban_stats = get_sweep_stats(sweep_id=\"5vnntqcp\", file_prefix=\"xlstm_bban\", save=True, load=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "xlstm_anbn_df, xlstm_anbn_stats = get_sweep_stats(sweep_id=\"0xws3drd\", file_prefix=\"xlstm_anbn\", save=True, load=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "xlstm_anbncn_df, xlstm_anbncn_stats = get_sweep_stats(sweep_id=\"krvkg6dj\", file_prefix=\"xlstm_anbncn\", save=True, load=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "xlstm_dyck_df, xlstm_dyck_stats = get_sweep_stats(sweep_id=\"rp0zyg2c\", file_prefix=\"xlstm_dyck\", save=True, load=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "xlstm_cs_dyck_df, xlstm_cs_dyck_stats = get_sweep_stats(sweep_id=\"7ebw68ab\", file_prefix=\"xlstm_cs_dyck\", save=True, load=True)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ban_df = pd.concat([ban_df, xlstm_ban_df])\n",
    "ban_stats = grouped_rule_stats(ban_df)\n",
    "\n",
    "bban_df = pd.concat([bban_df, xlstm_bban_df])\n",
    "bban_stats = grouped_rule_stats(bban_df)\n",
    "\n",
    "anbn_df = pd.concat([anbn_df, xlstm_anbn_df])\n",
    "anbn_stats = grouped_rule_stats(anbn_df)\n",
    "\n",
    "anbncn_df_merged = pd.concat([anbncn_df_merged, xlstm_anbncn_df])\n",
    "anbncn_stats = grouped_rule_stats(anbncn_df_merged)\n",
    "\n",
    "dyck_df = pd.concat([dyck_df, xlstm_dyck_df])\n",
    "dyck_stats = grouped_rule_stats(dyck_df)\n",
    "\n",
    "cs_dyck_df_merged = pd.concat([cs_dyck_df_merged, xlstm_cs_dyck_df])\n",
    "cs_dyck_stats = grouped_rule_stats(cs_dyck_df_merged)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameter search"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hyper_ban_df, hyper_ban_stats = get_sweep_stats(sweep_id=\"nza9ka3b\", file_prefix=\"hyper_ban\", save=True, load=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hyper_bban_df, hyper_bban_stats = get_sweep_stats(sweep_id=\"6fpd9uqg\", file_prefix=\"hyper_bban\", save=True, load=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hyper_anbn_df, hyper_anbn_stats = get_sweep_stats(sweep_id=\"amsk1ba7\", file_prefix=\"hyper_anbn\", save=True, load=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hyper_anbncn_df, hyper_anbncn_stats = get_sweep_stats(sweep_id=\"5prt0zmv\", file_prefix=\"hyper_anbncn\", save=True, load=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hyper_dyck_df, hyper_dyck_stats = get_sweep_stats(sweep_id=\"2r7j2cfm\", file_prefix=\"hyper_dyck\", save=True, load=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hyper_cs_dyck_df, hyper_cs_dyck_stats = get_sweep_stats(sweep_id=\"nakt9wnj\", file_prefix=\"hyper_cs_dyck\", save=True, load=True)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Transformer size ablation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "transformer_size_ban_df, transformer_size_ban_stats = get_sweep_stats(sweep_id=\"r6gelh9k\", file_prefix=\"transformer_size_ban\", save=True, load=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "transformer_size_bban_df, transformer_size_bban_stats = get_sweep_stats(sweep_id=\"53nmwmq1\", file_prefix=\"transformer_size_bban\", save=True, load=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "transformer_size_anbn_df, transformer_size_anbn_stats = get_sweep_stats(sweep_id=\"ddfjwbsl\", file_prefix=\"transformer_size_anbn\", save=True, load=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "transformer_size_anbncn_df, transformer_size_anbncn_stats = get_sweep_stats(sweep_id=\"yv9ajwdv\", file_prefix=\"transformer_size_anbncn\", save=True, load=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "transformer_size_dyck_df, transformer_size_dyck_stats = get_sweep_stats(sweep_id=\"v672gglg\", file_prefix=\"transformer_size_dyck\", save=True, load=True)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Number of all runs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(ban_df) + len(ban_sampling_df) + len(bban_df) + len(bban_sampling_df) + len(anbn_df) + len(anbn_sampling_df) + len(anbn_parity_df) + len(anbncn_df_merged) + len(anbncn_sampling_df) + len(dyck_df) + len(dyck_sampling_df) + len(cs_dyck_df_merged) + len(cs_dyck_sampling_df) + len(xlstm_ban_df) + len(xlstm_bban_df) + len(xlstm_anbn_df) + len(xlstm_anbncn_df) + len(xlstm_dyck_df) + len(xlstm_cs_dyck_df) + len(hyper_ban_df) + len(hyper_bban_df) + len(hyper_anbn_df) + len(hyper_anbncn_df) + len(hyper_dyck_df) + len(hyper_cs_dyck_df) + len(transformer_size_ban_df) + len(transformer_size_bban_df) + len(transformer_size_anbn_df) + len(transformer_size_anbncn_df) + len(transformer_size_dyck_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Human study"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "human_df = pd.read_excel(\"human_study.xlsx\")\n",
    "\n",
    "# fill nan with empty string\n",
    "human_df = human_df.fillna(\"\")\n",
    "\n",
    "# fill \"already completed\" with empty string\n",
    "human_df = human_df.replace(\"already completed\", \"\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prompts = list(human_df.columns[1:])\n",
    "# remove whitespace from beetween characters in the prompts\n",
    "prompts = [\"\".join(prompt.split()) for prompt in prompts]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# overwrite columns names in df\n",
    "human_df.columns = [\"timestamp\"] +prompts"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "A = A_token.item()\n",
    "B = B_token.item()\n",
    "OB = OPENING_BRACKET_token.item()\n",
    "OP = OPENING_PARENTHESIS_token.item()\n",
    "CB = CLOSING_BRACKET_token.item()\n",
    "CP = CLOSING_PARENTHESIS_token.item()\n",
    "\n",
    "def char2token(char):\n",
    "    char = char.upper()\n",
    "    if char == \"A\":\n",
    "        return A\n",
    "    elif char == \"B\":\n",
    "        return B\n",
    "    elif char == \"(\":\n",
    "        return OP\n",
    "    elif char == \")\":\n",
    "        return CP\n",
    "    elif char == \"[\":\n",
    "        return OB\n",
    "    elif char == \"]\":\n",
    "        return CB\n",
    "    else:\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# tokenize prompts\n",
    "prompts_tokenized = [[char2token(c) for c in prompt] for prompt in prompts]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenized_human_df = human_df.copy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for prompt, prompt_tokenized in zip(prompts, prompts_tokenized):\n",
    "\n",
    "    # get the column by prompt\n",
    "    col = human_df[prompt]\n",
    "    col_stripped = [\"\".join(prompt.split()) for prompt in col]\n",
    "    col_tokenized = [[char2token(c) for c in prompt] for prompt in col_stripped]\n",
    "\n",
    "    tokenized_human_df[prompt] = col_tokenized\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "anbn_r1_human = []\n",
    "anbn_r2_completion_human = []\n",
    "\n",
    "dyck_r1_human = []\n",
    "dyck_r2_completion_human = []\n",
    "\n",
    "ban_r1_human = []\n",
    "ban_r2_completion_human = []\n",
    "from rule_extrapolation.data import check_same_number_as_bs, check_as_before_bs, check_even_number_of_as, check_begins_with_b, check_matched_brackets, check_matched_parentheses\n",
    "import torch\n",
    "\n",
    "for idx, (prompt, prompt_tokenized) in enumerate(zip(prompts, prompts_tokenized)):\n",
    "    # get the column by prompt\n",
    "    col = tokenized_human_df[prompt]\n",
    "\n",
    "    # iterate over the rows\n",
    "    for completion in col:\n",
    "\n",
    "        if None in completion:\n",
    "            continue\n",
    "\n",
    "        # add the tokenized prompt\n",
    "        completed_prompt = torch.tensor(prompt_tokenized.copy() + completion)\n",
    "        completion = torch.tensor(completion)\n",
    "        # print(completion)\n",
    "\n",
    "        if idx < 4: # anbn, idx 4 is in-distribution\n",
    "            anbn_r1_human.append(check_same_number_as_bs(completed_prompt))\n",
    "            anbn_r2_completion_human.append(True if len(completion)==0 else check_as_before_bs(completion))\n",
    "        elif 4 < idx <=9    : # dyck\n",
    "            dyck_r1_human.append(check_matched_brackets(completed_prompt[2:]))\n",
    "            dyck_r2_completion_human.append(True if len(completion)==0 else check_matched_parentheses(completion))\n",
    "        else: # ban\n",
    "            ban_r1_human.append(check_even_number_of_as(completed_prompt))\n",
    "            ban_r2_completion_human.append(True if len(completion)==0 else check_begins_with_b(completion))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print accuracies\n",
    "print(f\"anbn R1: {np.mean(anbn_r1_human)}\")\n",
    "print(f\"anbn R2: {np.mean(anbn_r2_completion_human)}\")\n",
    "print(f\"dyck R1: {np.mean(dyck_r1_human)}\"\n",
    ")\n",
    "print(f\"dyck R2: {np.mean(dyck_r2_completion_human)}\")\n",
    "print(f\"ban R1: {np.mean(ban_r1_human)}\")\n",
    "print(f\"ban R2: {np.mean(ban_r2_completion_human)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "human_stats = {}\n",
    "human_stats[\"baN\"] = {\n",
    "    \"ood_rule_1\": np.mean(ban_r1_human),\n",
    "    \"ood_rule_2_completion\": np.mean(ban_r2_completion_human)\n",
    "}\n",
    "\n",
    "human_stats[\"aNbN\"] = {\n",
    "    \"ood_rule_1\": np.mean(anbn_r1_human),\n",
    "    \"ood_rule_2_completion\": np.mean(anbn_r2_completion_human)\n",
    "}\n",
    "\n",
    "# human_stats[\"Dyck\"] = {\n",
    "#     \"ood_rule_1\": np.mean(dyck_r1_human),\n",
    "#     \"ood_rule_2_completion\": np.mean(dyck_r2_completion_human)\n",
    "# }"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Chance levels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "chance_stats = {}\n",
    "chance_stats[\"baN\"] = {\n",
    "    \"ood_rule_1\": 0.5,\n",
    "    \"ood_rule_2_completion\": 1./3\n",
    "}\n",
    "\n",
    "chance_stats[\"bbaN\"] = {\n",
    "    \"ood_rule_1\": 0.5,\n",
    "    \"ood_rule_2_completion\": 0.75\n",
    "}\n",
    "\n",
    "\n",
    "chance_stats[\"aNbN\"] = {\n",
    "    \"ood_rule_1\": 0.154,\n",
    "    \"ood_rule_2_completion\": 0.4445\n",
    "}\n",
    "chance_stats[\"Dyck\"] = {\n",
    "    \"ood_rule_1\": 0.1273,\n",
    "    \"ood_rule_2_completion\": 0.382\n",
    "}\n",
    "\n",
    "chance_stats[\"CS Dyck\"] = {\n",
    "    \"ood_rule_1\": 0.1273,\n",
    "    \"ood_rule_2_completion\": 0.382\n",
    "}\n",
    "\n",
    "chance_stats[\"aNbNcN\"] = {\n",
    "    \"ood_rule_1\": 0.00334,\n",
    "    \"ood_rule_2_completion\": 0.5925\n",
    "}\n",
    "\n",
    "chance_stats[\"CS Dyck\"] = {\n",
    "    \"ood_rule_1\": 0.1273,\n",
    "    \"ood_rule_2_completion\": 0.382\n",
    "}\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Plots"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## helper functions\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_loss_vs_rules(df, stats, cmap=\"coolwarm\", TICK_PADDING=2, LABELPAD=1, filename=None):\n",
    "\n",
    "    colors = {\n",
    "        \"transformer\": \"tab:blue\",\n",
    "        \"lstm\": \"tab:orange\",\n",
    "        \"linear\": \"tab:green\",\n",
    "        \"mamba\": \"tab:red\"\n",
    "        }\n",
    "\n",
    "\n",
    "    fig = plt.figure(figsize=figsizes.icml2022_full(nrows=1, ncols=2)['figure.figsize'])\n",
    "    ax = fig.add_subplot(121)\n",
    "    ax.grid(True, which=\"both\", ls=\"-.\")\n",
    "    ax.set_axisbelow(True)\n",
    "    for model in stats[\"val_loss\"].groups.keys():\n",
    "\n",
    "        im = ax.scatter(df[df.model == model].min_val_loss,\n",
    "                        100 * df[df.model == model].ood_rule_1_accuracy4min_val_loss, c=colors[model], label=model.capitalize() if model != \"lstm\" else model.upper())\n",
    "    ax.set_ylabel(\"R1 \\%\", labelpad=LABELPAD)\n",
    "    ax.set_xlabel(\"Minimum test loss\", labelpad=LABELPAD)\n",
    "    # plt.legend()\n",
    "    ax.tick_params(axis='both', which='major', pad=TICK_PADDING)\n",
    "    ax = fig.add_subplot(122)\n",
    "    ax.grid(True, which=\"both\", ls=\"-.\")\n",
    "    ax.set_axisbelow(True)\n",
    "    for model in stats[\"val_loss\"].groups.keys():\n",
    "        im = ax.scatter(df[df.model == model].min_val_loss,\n",
    "                        100 * df[df.model == model].ood_rule_2_completion_accuracy4min_val_loss, c=colors[model], label=model.capitalize() if model != \"lstm\" else model.upper())\n",
    "    ax.set_ylabel(\"R2 completion (\\%)\", labelpad=LABELPAD)\n",
    "    ax.set_xlabel(\"Minimum test loss\", labelpad=LABELPAD)\n",
    "    plt.legend(loc=\"center right\", bbox_to_anchor=(1.75, 0.5))\n",
    "    ax.tick_params(axis='both', which='major', pad=TICK_PADDING)\n",
    "\n",
    "    if filename is not None:\n",
    "        plt.savefig(f\"{filename}.svg\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## baN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_loss_vs_rules(ban_df, ban_stats, filename=\"ban_loss_vs_rules\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rule_stats2string_per_model(ban_stats, include_r2=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## bbaN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_loss_vs_rules(bban_df, bban_stats, filename=\"bban_loss_vs_rules\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rule_stats2string_per_model(bban_stats)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## aNbN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_loss_vs_rules(anbn_df, anbn_stats, filename=\"anbn_loss_vs_rules\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_loss_vs_rules(anbn_parity_df, anbn_parity_stats, filename=\"anbn_loss_vs_rules\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rule_stats2string_per_model(anbn_stats)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## aNbNcN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_loss_vs_rules(anbncn_df, anbncn_stats, filename=\"anbncn_loss_vs_rules\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rule_stats2string_per_model(anbncn_stats)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dyck"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_loss_vs_rules(dyck_df, dyck_stats, filename=\"dyck_loss_vs_rules\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rule_stats2string_per_model(dyck_stats)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Context-sensitive Dyck"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TICK_PADDING = 2\n",
    "LABELPAD = 1\n",
    "cmap = \"coolwarm\"\n",
    "\n",
    "\n",
    "stats_dict = {\n",
    "    # \"baN\": grouped_rule_stats(pd.concat([ban_df, xlstm_ban_df])),\n",
    "    # \"bbaN\": grouped_rule_stats(pd.concat([bban_df, xlstm_bban_df])),\n",
    "    # \"aNbN\": grouped_rule_stats(pd.concat([anbn_df, xlstm_anbn_df])),\n",
    "    # \"aNbNcN\": grouped_rule_stats(pd.concat([anbncn_df_merged, xlstm_anbncn_df])),\n",
    "    # \"Dyck\": grouped_rule_stats(pd.concat([dyck_df, xlstm_dyck_df])),\n",
    "    \"CS Dyck\": grouped_rule_stats(pd.concat([cs_dyck_df_merged, xlstm_cs_dyck_df]))\n",
    "}\n",
    "\n",
    "labels = [\n",
    "    # r\"$b\\alpha$\",\n",
    "    # r\"$b^na^{2m}$\",\n",
    "    # r\"$a^nb^n$\",\n",
    "    # r\"$a^nb^nc^n$\",\n",
    "    # \"Dyck\",\n",
    "    \"CS Dyck\",\n",
    "]\n",
    "\n",
    "colors = {\n",
    "        \"transformer\": \"tab:blue\",\n",
    "        \"lstm\": \"tab:orange\",\n",
    "        \"linear\": \"tab:green\",\n",
    "        \"mamba\": \"tab:red\",\n",
    "    # \"human\" : \"black\",\n",
    "    \"xlstm\": \"purple\"\n",
    "        }\n",
    "\n",
    "\n",
    "x_pos = list(range(len(stats_dict)))\n",
    "x_offsets = [-0.35, -0.175, 0., .175, 0.35]\n",
    "x_factor = 1/ len(stats_dict)\n",
    "width = 0.35\n",
    "x_stretch = 3\n",
    "x_pos = [x*x_stretch for x in x_pos]\n",
    "\n",
    "fig = plt.figure(figsize=figsizes.neurips2022(nrows=1, ncols=3, tight_layout=True, rel_width=3)['figure.figsize'])\n",
    "\n",
    "ax = fig.add_subplot(121)\n",
    "\n",
    "\n",
    "models =  colors.keys()\n",
    "\n",
    "print(\"--------------------\")\n",
    "print(\"R1\")\n",
    "print(\"--------------------\")\n",
    "\n",
    "for x, (grammar, stats) in enumerate(stats_dict.items()):\n",
    "    #\n",
    "    if grammar in chance_stats.keys():\n",
    "        chance = chance_stats[grammar][\"ood_rule_1\"]\n",
    "        rectangle = matplotlib.patches.Rectangle((x_stretch*(x-0.5),0), width=x_stretch, height=100*chance, color='gray', alpha=.35)\n",
    "        ax.add_patch(rectangle)\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "\n",
    "        if model not in stats[\"ood_rule_1\"].groups.keys():\n",
    "            print(f\"Model {model} not in {grammar}\")\n",
    "            continue\n",
    "        mean = stats[\"ood_rule_1\"].get_group(model).mean()\n",
    "        std = stats[\"ood_rule_1\"].get_group(model).std()\n",
    "\n",
    "        print(f\"{model=} {mean} {std}\")\n",
    "\n",
    "\n",
    "\n",
    "        if mean < 0.01:\n",
    "            ax.errorbar(x_stretch*(x + x_offsets[i]), 100 * mean, yerr=10 * std, fmt=\"o\",  label=model, c=colors[model])\n",
    "        else:\n",
    "            ax.bar(x_stretch*(x + x_offsets[i]), 100 * mean, yerr=10 * std, width=width,  label=model, color=colors[model])\n",
    "\n",
    "\n",
    "    ax.axvline(x_stretch*(x+0.5), color='black', linestyle='--', linewidth=0.5)\n",
    "\n",
    "\n",
    "ax.set_ylabel(\"R1 (\\%)\", labelpad=LABELPAD)\n",
    "\n",
    "# set xtick names\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_xlim(x_stretch*x_offsets[0]-.35,x_stretch*(len(stats_dict)-1+x_offsets[-1])+.25)\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "print(\"--------------------\")\n",
    "print(\"R2 completion\")\n",
    "print(\"--------------------\")\n",
    "for x, (grammar, stats) in enumerate(stats_dict.items()):\n",
    "\n",
    "    if grammar in chance_stats.keys():\n",
    "        chance = chance_stats[grammar][\"ood_rule_2_completion\"]\n",
    "        rectangle = matplotlib.patches.Rectangle((x_stretch*(x-0.5),0), width=x_stretch, height=100*chance, color='gray', alpha=0.35)\n",
    "        ax2.add_patch(rectangle)\n",
    "\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "\n",
    "\n",
    "        if model not in stats[\"ood_rule_2_completion\"].groups.keys():\n",
    "            continue\n",
    "        mean = stats[\"ood_rule_2_completion\"].get_group(model).mean()\n",
    "        std = stats[\"ood_rule_2_completion\"].get_group(model).std()\n",
    "\n",
    "        print(f\"{model=} {mean} {std}\")\n",
    "\n",
    "        if mean < 0.01:\n",
    "            ax2.errorbar(x_stretch*(x + x_offsets[i]), 100 * mean, yerr=10 * std, fmt=\"o\",  label=model, c=colors[model])\n",
    "        else:\n",
    "            ax2.bar(x_stretch*(x + x_offsets[i]), 100 * mean, yerr=10 * std, width=width,  label=model, color=colors[model])\n",
    "\n",
    "\n",
    "    ax2.axvline(x_stretch*(x+0.5), color='black', linestyle='--', linewidth=0.5)\n",
    "\n",
    "\n",
    "# set xtick names\n",
    "ax2.set_xticks(x_pos)\n",
    "ax2.set_xticklabels(labels)\n",
    "ax2.set_ylabel(\"R2 completion (\\%)\", labelpad=LABELPAD)\n",
    "ax2.set_xlim(x_stretch*x_offsets[0]-.35,x_stretch*(len(stats_dict)-1+x_offsets[-1])+.25)\n",
    "\n",
    "handles = [mlines.Line2D([], [], color=colors[model], marker='o', label=(model.capitalize() if model != \"xlstm\" else \"xLSTM\") if model != \"lstm\" else model.upper()) for model in models] + [matplotlib.patches.Patch(color='gray', alpha=0.35, label='Chance-level')]\n",
    "ax2.legend(handles=handles, loc=\"center right\", bbox_to_anchor=(1.5, 0.5))#, loc='upper center',  ncol=4)\n",
    "\n",
    "\n",
    "\n",
    "# plt.legend()\n",
    "ax.tick_params(axis='both', which='major', pad=TICK_PADDING)\n",
    "ax.set_ylim(0, 100)\n",
    "ax2.set_ylim(0, 100)\n",
    "\n",
    "plt.savefig(\"ood_summary_cs_dyck.svg\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cs_dyck_df.model.unique()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rule_stats2string_per_model(grouped_rule_stats(pd.concat([cs_dyck_df_merged, xlstm_cs_dyck_df])), include_r2=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plot for all languages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TICK_PADDING = 2\n",
    "LABELPAD = 1\n",
    "cmap = \"coolwarm\"\n",
    "\n",
    "\n",
    "stats_dict = {\n",
    "    \"baN\": grouped_rule_stats(pd.concat([ban_df, xlstm_ban_df])),\n",
    "    \"bbaN\": grouped_rule_stats(pd.concat([bban_df, xlstm_bban_df])),\n",
    "    \"aNbN\": grouped_rule_stats(pd.concat([anbn_df, xlstm_anbn_df])),\n",
    "    \"aNbNcN\": grouped_rule_stats(pd.concat([anbncn_df_merged, xlstm_anbncn_df])),\n",
    "    \"Dyck\": grouped_rule_stats(pd.concat([dyck_df, xlstm_dyck_df])),\n",
    "    \"CS Dyck\": grouped_rule_stats(pd.concat([cs_dyck_df_merged, xlstm_cs_dyck_df]))\n",
    "}\n",
    "\n",
    "labels = [\n",
    "    r\"$b\\alpha$\",\n",
    "    r\"$b^na^{2m}$\",\n",
    "    r\"$a^nb^n$\",\n",
    "    r\"$a^nb^nc^n$\",\n",
    "    \"Dyck\",\n",
    "    \"CS Dyck\",\n",
    "]\n",
    "\n",
    "colors = {\n",
    "        \"transformer\": \"tab:blue\",\n",
    "        \"lstm\": \"tab:orange\",\n",
    "        \"linear\": \"tab:green\",\n",
    "        \"mamba\": \"tab:red\",\n",
    "    # \"human\" : \"black\",\n",
    "    \"xlstm\": \"purple\"\n",
    "        }\n",
    "\n",
    "\n",
    "x_pos = list(range(len(stats_dict)))\n",
    "x_offsets = [-0.35, -0.175, 0., .175, 0.35]\n",
    "x_factor = 1/ len(stats_dict)\n",
    "width = 0.35\n",
    "x_stretch = 3\n",
    "x_pos = [x*x_stretch for x in x_pos]\n",
    "\n",
    "fig = plt.figure(figsize=figsizes.neurips2022(nrows=1, ncols=3, tight_layout=True, rel_width=3)['figure.figsize'])\n",
    "\n",
    "ax = fig.add_subplot(121)\n",
    "\n",
    "\n",
    "models =  colors.keys()\n",
    "for x, (grammar, stats) in enumerate(stats_dict.items()):\n",
    "    #\n",
    "    if grammar in chance_stats.keys():\n",
    "        chance = chance_stats[grammar][\"ood_rule_1\"]\n",
    "        rectangle = matplotlib.patches.Rectangle((x_stretch*(x-0.5),0), width=x_stretch, height=100*chance, color='gray', alpha=.35)\n",
    "        ax.add_patch(rectangle)\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "\n",
    "        if model not in stats[\"ood_rule_1\"].groups.keys():\n",
    "            print(f\"Model {model} not in {grammar}\")\n",
    "            continue\n",
    "        mean = stats[\"ood_rule_1\"].get_group(model).mean()\n",
    "        std = stats[\"ood_rule_1\"].get_group(model).std()\n",
    "\n",
    "\n",
    "\n",
    "        if mean < 0.01:\n",
    "            ax.errorbar(x_stretch*(x + x_offsets[i]), 100 * mean, yerr=10 * std, fmt=\"o\",  label=model, c=colors[model])\n",
    "        else:\n",
    "            ax.bar(x_stretch*(x + x_offsets[i]), 100 * mean, yerr=10 * std, width=width,  label=model, color=colors[model])\n",
    "\n",
    "\n",
    "    ax.axvline(x_stretch*(x+0.5), color='black', linestyle='--', linewidth=0.5)\n",
    "\n",
    "\n",
    "ax.set_ylabel(\"R1 (\\%)\", labelpad=LABELPAD)\n",
    "\n",
    "# set xtick names\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_xlim(x_stretch*x_offsets[0]-.35,x_stretch*(len(stats_dict)-1+x_offsets[-1])+.25)\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "for x, (grammar, stats) in enumerate(stats_dict.items()):\n",
    "\n",
    "    if grammar in chance_stats.keys():\n",
    "        chance = chance_stats[grammar][\"ood_rule_2_completion\"]\n",
    "        rectangle = matplotlib.patches.Rectangle((x_stretch*(x-0.5),0), width=x_stretch, height=100*chance, color='gray', alpha=0.35)\n",
    "        ax2.add_patch(rectangle)\n",
    "\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "\n",
    "\n",
    "        if model not in stats[\"ood_rule_2_completion\"].groups.keys():\n",
    "            continue\n",
    "        mean = stats[\"ood_rule_2_completion\"].get_group(model).mean()\n",
    "        std = stats[\"ood_rule_2_completion\"].get_group(model).std()\n",
    "\n",
    "        if mean < 0.01:\n",
    "            ax2.errorbar(x_stretch*(x + x_offsets[i]), 100 * mean, yerr=10 * std, fmt=\"o\",  label=model, c=colors[model])\n",
    "        else:\n",
    "            ax2.bar(x_stretch*(x + x_offsets[i]), 100 * mean, yerr=10 * std, width=width,  label=model, color=colors[model])\n",
    "\n",
    "\n",
    "    ax2.axvline(x_stretch*(x+0.5), color='black', linestyle='--', linewidth=0.5)\n",
    "\n",
    "\n",
    "# set xtick names\n",
    "ax2.set_xticks(x_pos)\n",
    "ax2.set_xticklabels(labels)\n",
    "ax2.set_ylabel(\"R2 completion (\\%)\", labelpad=LABELPAD)\n",
    "ax2.set_xlim(x_stretch*x_offsets[0]-.35,x_stretch*(len(stats_dict)-1+x_offsets[-1])+.25)\n",
    "\n",
    "handles = [mlines.Line2D([], [], color=colors[model], marker='o', label=(model.capitalize() if model != \"xlstm\" else \"xLSTM\") if model != \"lstm\" else model.upper()) for model in models] + [matplotlib.patches.Patch(color='gray', alpha=0.35, label='Chance-level')]\n",
    "ax2.legend(handles=handles, loc=\"center right\", bbox_to_anchor=(1.5, 0.5))#, loc='upper center',  ncol=4)\n",
    "\n",
    "\n",
    "\n",
    "# plt.legend()\n",
    "ax.tick_params(axis='both', which='major', pad=TICK_PADDING)\n",
    "ax.set_ylim(0, 100)\n",
    "ax2.set_ylim(0, 100)\n",
    "\n",
    "plt.savefig(\"ood_summary_xlstm.svg\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "[len(x) for x in stats_dict.values()]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plot for sampling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TICK_PADDING = 2\n",
    "LABELPAD = 1\n",
    "cmap = \"coolwarm\"\n",
    "\n",
    "\n",
    "stats_dict = {\n",
    "    \"baN\": ban_sampling_stats,\n",
    "    \"bbaN\": bban_sampling_stats,\n",
    "    \"aNbN\": anbn_sampling_stats,\n",
    "    \"aNbNcN\": anbncn_sampling_stats,\n",
    "    \"Dyck\": dyck_sampling_stats,\n",
    "}\n",
    "\n",
    "labels = [\n",
    "    r\"$b\\alpha$\",\n",
    "    r\"$b^na^{2m}$\",\n",
    "    r\"$a^nb^n$\",\n",
    "    r\"$a^nb^nc^n$\",\n",
    "    \"Dyck\"\n",
    "]\n",
    "\n",
    "colors = {\n",
    "        \"transformer\": \"tab:blue\",\n",
    "        \"lstm\": \"tab:orange\",\n",
    "        \"linear\": \"tab:green\",\n",
    "        \"mamba\": \"tab:red\",\n",
    "    # \"human\" : \"black\",\n",
    "    # \"chance\": \"purple\"\n",
    "        }\n",
    "\n",
    "\n",
    "x_pos = list(range(len(stats_dict)))\n",
    "x_offsets = [-0.3, -0.1, .1, 0.3]\n",
    "x_factor = 1/ len(stats_dict)\n",
    "width = 0.35\n",
    "x_stretch = 3\n",
    "x_pos = [x*x_stretch for x in x_pos]\n",
    "\n",
    "fig = plt.figure(figsize=figsizes.neurips2022(nrows=1, ncols=3, tight_layout=True, rel_width=2)['figure.figsize'])\n",
    "\n",
    "ax = fig.add_subplot(121)\n",
    "# ax.grid(True, which=\"both\", ls=\"-.\")\n",
    "# ax.set_axisbelow(True)\n",
    "\n",
    "models =  colors.keys()\n",
    "for x, (grammar, stats) in enumerate(stats_dict.items()):\n",
    "    #\n",
    "    if grammar in chance_stats.keys():\n",
    "        chance = chance_stats[grammar][\"ood_rule_1\"]\n",
    "        rectangle = matplotlib.patches.Rectangle((x_stretch*(x-0.5),0), width=x_stretch, height=100*chance, color='gray', alpha=.35)\n",
    "        ax.add_patch(rectangle)\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "\n",
    "\n",
    "        if model not in stats[\"ood_rule_1\"].groups.keys():\n",
    "            continue\n",
    "        mean = stats[\"ood_rule_1\"].get_group(model).mean()\n",
    "        std = stats[\"ood_rule_1\"].get_group(model).std()\n",
    "\n",
    "\n",
    "\n",
    "        if mean < 0.01:\n",
    "            ax.errorbar(x_stretch*(x + x_offsets[i]), 100 * mean, yerr=10 * std, fmt=\"o\",  label=model, c=colors[model])\n",
    "        else:\n",
    "            ax.bar(x_stretch*(x + x_offsets[i]), 100 * mean, yerr=10 * std, width=width,  label=model, color=colors[model])\n",
    "\n",
    "\n",
    "    ax.axvline(x_stretch*(x+0.5), color='black', linestyle='--', linewidth=0.5)\n",
    "\n",
    "\n",
    "ax.set_ylabel(\"R1 (\\%)\", labelpad=LABELPAD)\n",
    "\n",
    "# set xtick names\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_xlim(x_stretch*x_offsets[0]-.35,x_stretch*(len(stats_dict)-1+x_offsets[-1])+.25)\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "for x, (grammar, stats) in enumerate(stats_dict.items()):\n",
    "\n",
    "    if grammar in chance_stats.keys():\n",
    "        chance = chance_stats[grammar][\"ood_rule_2_completion\"]\n",
    "        rectangle = matplotlib.patches.Rectangle((x_stretch*(x-0.5),0), width=x_stretch, height=100*chance, color='gray', alpha=0.35)\n",
    "        ax2.add_patch(rectangle)\n",
    "\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "\n",
    "\n",
    "        if model not in stats[\"ood_rule_2_completion\"].groups.keys():\n",
    "            continue\n",
    "        mean = stats[\"ood_rule_2_completion\"].get_group(model).mean()\n",
    "        std = stats[\"ood_rule_2_completion\"].get_group(model).std()\n",
    "\n",
    "        if mean < 0.01:\n",
    "            ax2.errorbar(x_stretch*(x + x_offsets[i]), 100 * mean, yerr=10 * std, fmt=\"o\",  label=model, c=colors[model])\n",
    "        else:\n",
    "            ax2.bar(x_stretch*(x + x_offsets[i]), 100 * mean, yerr=10 * std, width=width,  label=model, color=colors[model])\n",
    "\n",
    "\n",
    "    ax2.axvline(x_stretch*(x+0.5), color='black', linestyle='--', linewidth=0.5)\n",
    "\n",
    "\n",
    "# set xtick names\n",
    "ax2.set_xticks(x_pos)\n",
    "ax2.set_xticklabels(labels)\n",
    "ax2.set_ylabel(\"R2 completion (\\%)\", labelpad=LABELPAD)\n",
    "ax2.set_xlim(x_stretch*x_offsets[0]-.35,x_stretch*(len(stats_dict)-1+x_offsets[-1])+.25)\n",
    "\n",
    "handles = [mlines.Line2D([], [], color=colors[model], marker='o', label=model.capitalize() if model != \"lstm\" else model.upper()) for model in models] + [matplotlib.patches.Patch(color='gray', alpha=0.35, label='Chance-level')]\n",
    "ax2.legend(handles=handles, loc=\"center right\", bbox_to_anchor=(1.5, 0.5))#, loc='upper center',  ncol=4)\n",
    "\n",
    "\n",
    "\n",
    "# plt.legend()\n",
    "ax.tick_params(axis='both', which='major', pad=TICK_PADDING)\n",
    "ax.set_ylim(0, 100)\n",
    "ax2.set_ylim(0, 100)\n",
    "\n",
    "plt.savefig(\"ood_summary_sampling.svg\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dyck_sampling_df.model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## aNbN parity"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rule_stats2string_per_model(grouped_rule_stats(anbn_parity_df), plot=(\"val_loss\", \"rule_1\", \"rule_3\", \"ood_rule_1\", \"ood_rule_3\"), include_r2=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TICK_PADDING = 2\n",
    "LABELPAD = 1\n",
    "cmap = \"coolwarm\"\n",
    "\n",
    "\n",
    "stats_dict = {\n",
    "    \"aNbN\": grouped_rule_stats(anbn_parity_df),\n",
    "}\n",
    "\n",
    "labels = [\n",
    "    r\"$a^nb^n$\",\n",
    "]\n",
    "\n",
    "colors = {\n",
    "        \"transformer\": \"tab:blue\",\n",
    "        \"lstm\": \"tab:orange\",\n",
    "        \"linear\": \"tab:green\",\n",
    "        \"mamba\": \"tab:red\",\n",
    "    # \"human\" : \"black\",\n",
    "    \"xlstm\": \"purple\"\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=figsizes.neurips2022(nrows=1, ncols=1, tight_layout=True, rel_width=1)['figure.figsize'])\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    model_runs = anbn_parity_df[anbn_parity_df.model == model]\n",
    "    print(\"------------------\")\n",
    "    print(f\"(OOD R1){model=} {100*model_runs.ood_rule_1_accuracy4min_val_loss.mean()} {100*model_runs.ood_rule_1_accuracy4min_val_loss.std()}\")\n",
    "    print(f\"(OOD R3){model=} {100*model_runs.ood_rule_1_accuracy4min_val_loss.mean()} {100*model_runs.ood_rule_1_accuracy4min_val_loss.std()}\")\n",
    "    print(\"------------------\")\n",
    "\n",
    "\n",
    "    ax.scatter(100*model_runs.ood_rule_1_accuracy4min_val_loss, 100*model_runs.ood_rule_3_accuracy4min_val_loss, c=colors[model], label=model.capitalize() if model != \"lstm\" else model.upper())\n",
    "\n",
    "\n",
    "\n",
    "ax.set_ylabel(\"R1 (\\%)\", labelpad=LABELPAD)\n",
    "ax.set_xlabel(\"R3 (\\%)\", labelpad=LABELPAD)\n",
    "\n",
    "# set xtick names\n",
    "\n",
    "\n",
    "handles = [mlines.Line2D([], [], color=colors[model], marker='o', label=(model.capitalize() if model != \"xlstm\" else \"xLSTM\") if model != \"lstm\" else model.upper()) for model in models]\n",
    "ax.legend(handles=handles, loc=\"center right\", bbox_to_anchor=(1.5, 0.5))#, loc='upper center',  ncol=4)\n",
    "\n",
    "\n",
    "\n",
    "# plt.legend()\n",
    "ax.tick_params(axis='both', which='major', pad=TICK_PADDING)\n",
    "ax.set_ylim(0, 100)\n",
    "ax.set_xlim(0, 100)\n",
    "plt.savefig(\"ood_anbn_parity.svg\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameter search plot"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TICK_PADDING = 2\n",
    "LABELPAD = 1\n",
    "cmap = \"coolwarm\"\n",
    "\n",
    "\n",
    "labels = [\n",
    "    r\"$b\\alpha$\",\n",
    "    r\"$b^na^{2m}$\",\n",
    "    r\"$a^nb^n$\",\n",
    "    r\"$a^nb^nc^n$\",\n",
    "    # \"Dyck\",\n",
    "    # \"CS Dyck\",\n",
    "]\n",
    "\n",
    "colors = {\n",
    "        \"transformer\": \"tab:blue\",\n",
    "        \"lstm\": \"tab:orange\",\n",
    "        \"linear\": \"tab:green\",\n",
    "        \"mamba\": \"tab:red\",\n",
    "    # \"human\" : \"black\",\n",
    "    # \"chance\": \"purple\"\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=figsizes.neurips2022(nrows=3, ncols=3, tight_layout=True, rel_width=2)['figure.figsize'])\n",
    "\n",
    "ax = fig.add_subplot(321)\n",
    "ax2 = fig.add_subplot(322)\n",
    "ax3 = fig.add_subplot(323)\n",
    "ax4 = fig.add_subplot(324)\n",
    "ax5 = fig.add_subplot(325)\n",
    "ax6 = fig.add_subplot(326)\n",
    "\n",
    "models =  colors.keys()\n",
    "optimizers = hyper_ban_df.optimizer.unique()\n",
    "lrs = hyper_ban_df.lr.unique()\n",
    "\n",
    "stats_dict_hyper = {\n",
    "    \"baN\": grouped_rule_stats(hyper_ban_df, [\"optimizer\", \"lr\", \"model\"]),\n",
    "    \"bbaN\": grouped_rule_stats(hyper_bban_df, [\"optimizer\", \"lr\", \"model\"]),\n",
    "    \"aNbN\": grouped_rule_stats(hyper_anbn_df, [\"optimizer\", \"lr\", \"model\"]),\n",
    "    \"aNbNcN\": grouped_rule_stats(hyper_anbncn_df, [\"optimizer\", \"lr\", \"model\"]),\n",
    "    # \"Dyck\": grouped_rule_stats(hyper_dyck_df, [\"optimizer\", \"lr\", \"model\"]),\n",
    "    # \"CS Dyck\": cs_dyck_stats,\n",
    "}\n",
    "\n",
    "\n",
    "x_pos = list(range(len(stats_dict_hyper)))\n",
    "x_offsets = [-0.3, -0.1, .1, 0.3]\n",
    "x_factor = 1/ len(stats_dict_hyper)\n",
    "width = 0.35\n",
    "x_stretch = 3\n",
    "x_pos = [x*x_stretch for x in x_pos]\n",
    "\n",
    "# plot_row(ax, None, stats_dict_hyper, optimizers[0], lrs[0],\"optimizer\", \"lr\")\n",
    "\n",
    "\n",
    "stats_dict = {\n",
    "    \"baN\": grouped_rule_stats(pd.concat([ban_df, xlstm_ban_df])),\n",
    "    \"bbaN\": grouped_rule_stats(pd.concat([bban_df, xlstm_bban_df])),\n",
    "    \"aNbN\": grouped_rule_stats(pd.concat([anbn_df, xlstm_anbn_df])),\n",
    "    \"aNbNcN\": grouped_rule_stats(pd.concat([anbncn_df_merged, xlstm_anbncn_df])),\n",
    "    # \"Dyck\": grouped_rule_stats(pd.concat([dyck_df, xlstm_dyck_df])),\n",
    "    # \"CS Dyck\": grouped_rule_stats(pd.concat([cs_dyck_df_merged, xlstm_cs_dyck_df]))\n",
    "}\n",
    "\n",
    "for x, (grammar, stats) in enumerate(stats_dict.items()):\n",
    "    #\n",
    "    if grammar in chance_stats.keys():\n",
    "        chance = chance_stats[grammar][\"ood_rule_1\"]\n",
    "        rectangle = matplotlib.patches.Rectangle((x_stretch*(x-0.5),0), width=x_stretch, height=100*chance, color='gray', alpha=.35)\n",
    "        ax.add_patch(rectangle)\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "\n",
    "        if model not in stats[\"ood_rule_1\"].groups.keys():\n",
    "            print(f\"Model {model} not in {grammar}\")\n",
    "            continue\n",
    "        mean = stats[\"ood_rule_1\"].get_group(model).mean()\n",
    "        std = stats[\"ood_rule_1\"].get_group(model).std()\n",
    "\n",
    "        if mean < 0.01:\n",
    "            ax.errorbar(x_stretch*(x + x_offsets[i]), 100 * mean, yerr=10 * std, fmt=\"o\",  label=model, c=colors[model])\n",
    "        else:\n",
    "            ax.bar(x_stretch*(x + x_offsets[i]), 100 * mean, yerr=10 * std, width=width,  label=model, color=colors[model])\n",
    "\n",
    "\n",
    "    ax.axvline(x_stretch*(x+0.5), color='black', linestyle='--', linewidth=0.5)\n",
    "\n",
    "\n",
    "ax.set_ylabel(\"R1 (\\%)\", labelpad=LABELPAD)\n",
    "\n",
    "# set xtick names\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_xlim(x_stretch*x_offsets[0]-.35,x_stretch*(len(stats_dict)-1+x_offsets[-1])+.25)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# plt.legend()\n",
    "ax.tick_params(axis='both', which='major', pad=TICK_PADDING)\n",
    "ax.set_ylim(0, 100)\n",
    "ax.set_title(f\"Fig. 1: optimizer: {optimizers[0]}, lr: {lrs[0]}\")\n",
    "\n",
    "\n",
    "plot_row(ax2, None, stats_dict_hyper, optimizers[1], lrs[0],\"optimizer\", \"lr\")\n",
    "plot_row(ax3, None, stats_dict_hyper, optimizers[0], lrs[1],\"optimizer\", \"lr\")\n",
    "plot_row(ax4, None, stats_dict_hyper, optimizers[1], lrs[1],\"optimizer\", \"lr\")\n",
    "plot_row(ax5, None, stats_dict_hyper, optimizers[0], lrs[2],\"optimizer\", \"lr\")\n",
    "plot_row(ax6, None, stats_dict_hyper, optimizers[1], lrs[2],\"optimizer\", \"lr\")\n",
    "\n",
    "# handles = [mlines.Line2D([], [], color=colors[model], marker='o',\n",
    "#                                  label=model.capitalize() if model != \"lstm\" else model.upper()) for model in models] + [\n",
    "#                       matplotlib.patches.Patch(color='gray', alpha=0.35, label='Chance-level')]\n",
    "# ax6.legend(handles=handles, loc=\"lower center\", ncol=6)\n",
    "\n",
    "\n",
    "plt.savefig(\"ood_summary_hyper.svg\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def plot_row(ax, ax2, stats_dict, row_key, col_key, row_label, col_label):\n",
    "\n",
    "    for x, (grammar, stats) in enumerate(stats_dict.items()):\n",
    "        #\n",
    "        if grammar in chance_stats.keys():\n",
    "            chance = chance_stats[grammar][\"ood_rule_1\"]\n",
    "            rectangle = matplotlib.patches.Rectangle((x_stretch * (x - 0.5), 0), width=x_stretch, height=100 * chance,\n",
    "                                                     color='gray', alpha=.35)\n",
    "            ax.add_patch(rectangle)\n",
    "\n",
    "        for i, model in enumerate(models):\n",
    "            # if model not in stats[\"ood_rule_1\"].groups.keys():\n",
    "            #     continue\n",
    "            try:\n",
    "                mean = stats[\"ood_rule_1\"].get_group((row_key, col_key, model)).mean()\n",
    "                std = stats[\"ood_rule_1\"].get_group((row_key, col_key, model)).std()\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            if mean < 0.01:\n",
    "                ax.errorbar(x_stretch * (x + x_offsets[i]), 100 * mean, yerr=10 * std, fmt=\"o\", label=model,\n",
    "                            c=colors[model])\n",
    "            else:\n",
    "                ax.bar(x_stretch * (x + x_offsets[i]), 100 * mean, yerr=10 * std, width=width, label=model,\n",
    "                       color=colors[model])\n",
    "\n",
    "        ax.axvline(x_stretch * (x + 0.5), color='black', linestyle='--', linewidth=0.5)\n",
    "    ax.set_ylabel(\"R1 (\\%)\", labelpad=LABELPAD)\n",
    "    # set xtick names\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_xlim(x_stretch * x_offsets[0] - .35, x_stretch * (len(stats_dict) - 1 + x_offsets[-1]) + .25)\n",
    "    ax.set_title(f\"{row_label}: {row_key}, {col_label}: {col_key}\")\n",
    "    ax.set_ylim(0, 100)\n",
    "\n",
    "    if ax2 is not None:\n",
    "        for x, (grammar, stats) in enumerate(stats_dict.items()):\n",
    "\n",
    "            if grammar in chance_stats.keys():\n",
    "                chance = chance_stats[grammar][\"ood_rule_2_completion\"]\n",
    "                rectangle = matplotlib.patches.Rectangle((x_stretch * (x - 0.5), 0), width=x_stretch, height=100 * chance,\n",
    "                                                         color='gray', alpha=0.35)\n",
    "                ax2.add_patch(rectangle)\n",
    "\n",
    "            for i, model in enumerate(models):\n",
    "\n",
    "                # if model not in stats[\"ood_rule_2_completion\"].groups.keys():\n",
    "                #     continue\n",
    "                try:\n",
    "                    mean = stats[\"ood_rule_2_completion\"].get_group((row_key, col_key, model)).mean()\n",
    "                    std = stats[\"ood_rule_2_completion\"].get_group((row_key, col_key, model)).std()\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "                if mean < 0.01:\n",
    "                    ax2.errorbar(x_stretch * (x + x_offsets[i]), 100 * mean, yerr=10 * std, fmt=\"o\", label=model,\n",
    "                                 c=colors[model])\n",
    "                else:\n",
    "                    ax2.bar(x_stretch * (x + x_offsets[i]), 100 * mean, yerr=10 * std, width=width, label=model,\n",
    "                            color=colors[model])\n",
    "\n",
    "            ax2.axvline(x_stretch * (x + 0.5), color='black', linestyle='--', linewidth=0.5)\n",
    "        # set xtick names\n",
    "        ax2.set_xticks(x_pos)\n",
    "        ax2.set_xticklabels(labels)\n",
    "        ax2.set_ylabel(\"R2 completion (\\%)\", labelpad=LABELPAD)\n",
    "        ax2.set_xlim(x_stretch * x_offsets[0] - .35, x_stretch * (len(stats_dict) - 1 + x_offsets[-1]) + .25)\n",
    "        handles = [mlines.Line2D([], [], color=colors[model], marker='o',\n",
    "                                 label=model.capitalize() if model != \"lstm\" else model.upper()) for model in models] + [\n",
    "                      matplotlib.patches.Patch(color='gray', alpha=0.35, label='Chance-level')]\n",
    "        ax2.legend(handles=handles, loc=\"center right\", bbox_to_anchor=(1.5, 0.5))  #, loc='upper center',  ncol=4)\n",
    "        # plt.legend()\n",
    "        ax2.set_title(f\"{row_label}: {row_key}, {col_label}: {col_key}\")\n",
    "        ax2.set_ylim(0, 100)\n",
    "\n",
    "    ax.tick_params(axis='both', which='major', pad=TICK_PADDING)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Transformer size ablation plot"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "colors = {\n",
    "        \"transformer\": \"tab:blue\",\n",
    "        # \"lstm\": \"tab:orange\",\n",
    "        # \"linear\": \"tab:green\",\n",
    "        # \"mamba\": \"tab:red\",\n",
    "    # \"human\" : \"black\",\n",
    "    # \"xlstm\": \"purple\"\n",
    "        }\n",
    "\n",
    "\n",
    "labels = [\n",
    "    r\"$b\\alpha$\",\n",
    "    r\"$b^na^{2m}$\",\n",
    "    r\"$a^nb^n$\",\n",
    "    r\"$a^nb^nc^n$\",\n",
    "    \"Dyck\"\n",
    "]\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=figsizes.neurips2022(nrows=3, ncols=3, tight_layout=True, rel_width=2)['figure.figsize'])\n",
    "\n",
    "\n",
    "ax = plt.subplot2grid((3,2), (0,0))\n",
    "ax2 = plt.subplot2grid((3,2), (0,1))\n",
    "ax3 =plt.subplot2grid((3,2), (1,0))\n",
    "ax4 =plt.subplot2grid((3,2), (1,1))\n",
    "ax5 =plt.subplot2grid((3,2), (2,0))\n",
    "ax6 =plt.subplot2grid((3,2), (2,1))\n",
    "# ax7 =plt.subplot2grid((6,2), (3,0))\n",
    "# ax8 =plt.subplot2grid((6,2), (3,1))\n",
    "# ax9 =plt.subplot2grid((6,2), (4,0))\n",
    "# ax10 =plt.subplot2grid((6,2), (4,1))\n",
    "# ax11=plt.subplot2grid((6,2), (5,0))\n",
    "# ax12 =plt.subplot2grid((6,2), (5,1))\n",
    "\n",
    "models =  colors.keys()\n",
    "num_heads = transformer_size_ban_df.num_heads.unique()\n",
    "num_decoder_layers = transformer_size_ban_df.num_decoder_layers.unique()\n",
    "\n",
    "stats_dict_transformer_size = {\n",
    "    \"baN\": grouped_rule_stats(transformer_size_ban_df, [\"num_heads\", \"num_decoder_layers\", \"model\"]),\n",
    "    \"bbaN\": grouped_rule_stats(transformer_size_bban_df, [\"num_heads\", \"num_decoder_layers\", \"model\"]),\n",
    "    \"aNbN\": grouped_rule_stats(transformer_size_anbn_df, [\"num_heads\", \"num_decoder_layers\", \"model\"]),\n",
    "    \"aNbNcN\": grouped_rule_stats(transformer_size_anbncn_df, [\"num_heads\", \"num_decoder_layers\", \"model\"]),\n",
    "    \"Dyck\": grouped_rule_stats(transformer_size_dyck_df, [\"num_heads\", \"num_decoder_layers\", \"model\"]),\n",
    "    # \"CS Dyck\": cs_dyck_stats,\n",
    "}\n",
    "\n",
    "x_pos = list(range(len(stats_dict_transformer_size)))\n",
    "x_offsets = [-0.3, -0.1, .1, 0.3]\n",
    "x_factor = 1/ len(stats_dict_transformer_size)\n",
    "width = 0.35\n",
    "x_stretch = 3\n",
    "x_pos = [x*x_stretch for x in x_pos]\n",
    "\n",
    "plot_row(ax, None, stats_dict_transformer_size, num_heads[0], num_decoder_layers[0], \"\\# Heads\", \"\\# Decoder layers\")\n",
    "plot_row(ax2, None, stats_dict_transformer_size, num_heads[1], num_decoder_layers[0],\"\\# Heads\", \"\\# Decoder layers\")\n",
    "plot_row(ax3, None, stats_dict_transformer_size, num_heads[0], num_decoder_layers[1],\"\\# Heads\", \"\\# Decoder layers\")\n",
    "plot_row(ax4, None, stats_dict_transformer_size, num_heads[1], num_decoder_layers[1],\"\\# Heads\", \"\\# Decoder layers\")\n",
    "plot_row(ax5, None, stats_dict_transformer_size, num_heads[0], num_decoder_layers[2],\"\\# Heads\", \"\\# Decoder layers\")\n",
    "plot_row(ax6, None, stats_dict_transformer_size, num_heads[1], num_decoder_layers[2],\"\\# Heads\", \"\\# Decoder layers\")\n",
    "\n",
    "handles = [mlines.Line2D([], [], color=colors[model], marker='o',\n",
    "                                 label=model.capitalize() if model != \"lstm\" else model.upper()) for model in models] + [\n",
    "                      matplotlib.patches.Patch(color='gray', alpha=0.35, label='Chance-level')]\n",
    "ax3.legend(handles=handles, loc=\"upper center\", ncol=2)\n",
    "\n",
    "plt.savefig(\"ood_summary_transformer_size.svg\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
